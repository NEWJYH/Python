{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3443596b",
   "metadata": {},
   "source": [
    "수업 목표\n",
    "\n",
    "데이터 과학자가 누구인지 어떤 역량을 요구하는지 이해합니다.\n",
    "\n",
    "도메인 전문성의 중요성을 이해합니다.\n",
    "\n",
    "머신러닝 업무 프로세스를 이해합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd13ce",
   "metadata": {},
   "source": [
    "실습 목표\n",
    "\n",
    "1. 머신러닝에서 도메인 전문성의 중요성을 이해합니다.\n",
    "\n",
    "2. 머신러닝 모델 구축에서 도메인 지식의 역할을 이해합니다.\n",
    "\n",
    "3. 머신러닝 모델의 성능을 높이는 과정을 이해합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97375470",
   "metadata": {},
   "source": [
    "목 차\n",
    "\n",
    "1. 데이터 과학자 Data Scientist\n",
    "\n",
    "2. 데이터 과학자의 업무 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c240de4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "784e9651",
   "metadata": {},
   "source": [
    "데이터 과학자는 누구이고 어떤 역량을 필요로 하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333ba8f",
   "metadata": {},
   "source": [
    "1. 데이터 과학자 Data Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b95716",
   "metadata": {},
   "source": [
    "데이터 과학자?\n",
    "\n",
    "데이터 과학은 컴퓨터를 활용해서\n",
    "데이터를 분석하고 현실의 문제들을 해결하는 것\n",
    "\n",
    "컴퓨터 활용   ↔   데이터 분석\n",
    "    ↖↘ 현실의 문제 ↙↗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df509a58",
   "metadata": {},
   "source": [
    "데이터 과학자에게 요구되는 실무능력은?\n",
    "\n",
    "프로그래밍 스킬     (머신러닝)      수학&통계학 지식\n",
    "         (위험지역)(데이터 과학)(전통적 통계분석)\n",
    "                 도메인 전문성\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b60bb",
   "metadata": {},
   "source": [
    "흔히들 말하는 데이터 과학자 Skill Sets\n",
    "\n",
    "Programming\n",
    "- 컴퓨터 과학 지식\n",
    "- 프로그래밍 언어(Python/R)\n",
    "- 데이터베이스 언어(SQL, NoSQL)\n",
    "- Relational Algebra\n",
    "- 병렬 처리 컴퓨팅\n",
    "- MapReduce 개념\n",
    "- Hadoop/Hive/Pig\n",
    "- AWS 같은 플랫폼 사용 경험\n",
    "\n",
    "Math & Statistics\n",
    "- 연구 계획(Experiment design)\n",
    "- Machine Learning\n",
    "- Statistical modeling\n",
    "- 베이지안 추론\n",
    "- 선형대수, 미적분\n",
    "- Supervised Learning\n",
    "- Unsupervised Learning\n",
    "- Optimization\n",
    "\n",
    "Domain Knowledge\n",
    "- 비지니스 이해/지식\n",
    "- Collaborative\n",
    "- 데이터에 대한 호기심\n",
    "- 전략적 사고/기획력\n",
    "- 문제 해결능력\n",
    "- Proactive/Creativity\n",
    "\n",
    "Communication\n",
    "- 상급자와의 원활한 의사소통 능력\n",
    "- 스토리텔링 능력\n",
    "- 데이터 기반 인사이트를 의사결정에 활용하는 능력\n",
    "- ppt, doc등 문서 작성 능력\n",
    "- 시각화(Visualization)\n",
    "- 발표/설득력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162d247",
   "metadata": {},
   "source": [
    "데이터 과학자!\n",
    "\n",
    "데이터 과학은 컴퓨터를 활용해서\n",
    "데이터를 분석하고 현실의 문제들을 해결하는 것\n",
    "\n",
    "↓ Data Scientist \n",
    "\n",
    "컴퓨터와 IT기술을 활용하고 프로그래밍을 할 수 있는 능력을 가진 사람이\n",
    "수학과 통계학 지식을 이용해서 도메인의 문제를 해결하는 사람"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c795a47c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46f0d650",
   "metadata": {},
   "source": [
    "Why Data Scientist is Unicorn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e4e6c",
   "metadata": {},
   "source": [
    "왜 유니콘이라고 부를까?\n",
    "\n",
    "- 엄청나게 뛰어나거나\n",
    "- 없다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a09b91",
   "metadata": {},
   "source": [
    "혼자서 다 못해\n",
    "\n",
    "Team Sports\n",
    "팀 : 비지니스 분석, 분석가, 시스템 개발자 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db51e827",
   "metadata": {},
   "source": [
    "프로젝트\n",
    "\n",
    "양, 기한"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f055fe",
   "metadata": {},
   "source": [
    "그래서 중요한 건 협업\n",
    "\n",
    "의사소통\n",
    "데이터 과학자, 비즈니스 실무자, IT 엔지니어 등\n",
    "\n",
    "가교 역할\n",
    "비즈니스 - 기술"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc707ba",
   "metadata": {},
   "source": [
    "문과생 데이터 과학자의 방향\n",
    "\n",
    "it first starts by providing you can do something.\n",
    "that you can make something - DJ Patil\n",
    "\n",
    "                데이터과학\n",
    "             ↗           ↖     \n",
    "       (위험 지역)         (전통적 통계 분석)\n",
    "             ↖ 도메인 전문 ↗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7eadc5",
   "metadata": {},
   "source": [
    "데이터 과학자에게 도메인 전문성이 중요한 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574a2d2",
   "metadata": {},
   "source": [
    "도메인 전문성의 중요성 (1)\n",
    "\n",
    "SNS        \n",
    "- 사람들의 상호작용 관계 원인 파악 -> 서비스 이탈하지 않는 모델\n",
    "- 과정 이해 -> 이탈하지 않기 위한 고민\n",
    "\n",
    "AU, CTR\n",
    "- 수익률 개선 프로젝트 \n",
    "- AU : Active User\n",
    "- CTR : click through ratio\n",
    "       (광고의 노출 횟수 대비 고객이 광고를 클릭하는 횟수)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9281ad",
   "metadata": {},
   "source": [
    "도메인 전문성의 중요성 (2)\n",
    "\n",
    "NSAID : \n",
    "- nonsteroidal antiinflammatory drug 비(非)스테로이드 항(抗)염증약\n",
    "\n",
    "Gastrointestinal Bleed : \n",
    "- 위장 \n",
    "\n",
    "어떤 사람들이 위출혈이 발생하는지? 의료적인 지식 필요\n",
    "데이터 수집, 코딩과정 중 오류 ? 프로세스에 대한 이해가 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a888d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83cd6364",
   "metadata": {},
   "source": [
    "머신러닝 업무 프로세스 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c3bbe",
   "metadata": {},
   "source": [
    "3. 데이터 과학자의 업무 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a8c74",
   "metadata": {},
   "source": [
    "데이터 과학은 예술이다?\n",
    "\n",
    "1. 반복필요\n",
    "2. 무에서 유 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8666e",
   "metadata": {},
   "source": [
    "이상적인 머신러닝 업무 프로세스\n",
    "\n",
    "1. 문제파악 문제 정의\n",
    "\n",
    "2. 데이터 준비\n",
    "\n",
    "3. 모델 구축 & 평가\n",
    "\n",
    "4. 결과 공유\n",
    "\n",
    "5. 모니터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18567299",
   "metadata": {},
   "source": [
    "현실의 머신러닝 업무 프로세스\n",
    "\n",
    "1. 문제파악 문제 정의\n",
    "\n",
    "2. 데이터 준비\n",
    "\n",
    "3. 모델 구축 & 평가\n",
    "\n",
    "4. 결과 공유\n",
    "\n",
    "5. 모니터링\n",
    "\n",
    "순번이 지속적으로 수정되고 계속적인 모니터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dada07",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65664ed2",
   "metadata": {},
   "source": [
    "각 업무 프로세스 별 세부내용  파악하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362f6703",
   "metadata": {},
   "source": [
    "1. 문제파악 및 문제 정의\n",
    "\n",
    "1) 비즈니스 문제 파악\n",
    "2) 머신러닝 문제로 전환\n",
    "3) 머신러닝 도입 필요성/가능성 체크\n",
    "4) 도입에 따른 효과검증 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f58f86",
   "metadata": {},
   "source": [
    "2. 데이터 준비\n",
    "\n",
    "1) 가능한 다양하고 많은 데이터 확보\n",
    "2) 머신러닝 도입할 시스템 설계\n",
    "3) 데이터 분석 및 이해 - Understanding\n",
    "4) 데이터 분석 및 이해 - Preprocessing\n",
    "5) 데이터 분석 및 이해 - Exploring\n",
    "6) Feature Engineering\n",
    "7) 학습, 검증, 테스트 데이터셋 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f63b9",
   "metadata": {},
   "source": [
    "3. 머신러닝 모델 구축 & 분석\n",
    "\n",
    "1) 사용할 모델/알고리즘 선택\n",
    "2) 실무적 제약사항 고려\n",
    "3) 하이퍼파라미터 설정\n",
    "4) 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c4971f",
   "metadata": {},
   "source": [
    "4. 결과 공유\n",
    "\n",
    "A. 코드 배포(Productionize)\n",
    "\n",
    "B. 보고서 작성, 결과정리 및 발표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d82a4",
   "metadata": {},
   "source": [
    "5. 모니터링\n",
    "\n",
    "1) 모델의 성능을 지속적으로 tracking\n",
    "\n",
    "2) 효과 검증 결과 tracking\n",
    "\n",
    "3) 지속적인 유지 보수 계획/실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8da50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b5f1f1f",
   "metadata": {},
   "source": [
    "머신러닝을 위한 데이터 과학자의 도구 알아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b18a2",
   "metadata": {},
   "source": [
    "Excel\n",
    "\n",
    "수백만 데이터, 핵심 기능, 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353eb4b0",
   "metadata": {},
   "source": [
    "머신러닝을 위한 데이터 과학자의 도구\n",
    "\n",
    "Python   \n",
    "\n",
    "R\n",
    "\n",
    "수억, 빅데이터 작업 최적화\n",
    "데이터 처리 가공유리\n",
    "시스템에 사용하기 편리\n",
    "\n",
    "Python \n",
    "1) 범용적, 웹, 앱, 데이터 분석\n",
    "2) R 머신러닝보다 좀더 빠름\n",
    "3) 딥러닝 프레임워크 + 속도가 더 빠르고 표준으로 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24326b2",
   "metadata": {},
   "source": [
    "Python 머신러닝 Tool Box\n",
    "\n",
    "IP[y]: IPython\n",
    "Jupyter\n",
    "NumPy\n",
    "Scipy\n",
    "pandas\n",
    "matplotlib\n",
    "scikit-learn\n",
    "TensorFlow\n",
    "\n",
    "엘리스 Tool 코딩교육"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2460df11",
   "metadata": {},
   "source": [
    "실습 순서\n",
    "데이터를 살펴보고\n",
    "직관과 기존 도메인 지식을 이용해\n",
    "심장 질환과 관련성이 높다고 생각되는\n",
    "요인 3가지를 선택한다.\n",
    "\n",
    "머신러닝 모델 학습 결과를 통해\n",
    "선택한 요인과 심장 질환의 연관성을 평가해본다.\n",
    "\n",
    "데이터 과학적 방법을 이용하여\n",
    "최고 정확도를 만들어낼 수 있는\n",
    "심장 질환의 핵심 요인들을 자유롭게 찾아본다.\n",
    "\n",
    "머신러닝 모델 학습 결과를 통해\n",
    "다양한 요인들을 조합해보며\n",
    "최고 정확도에 도전한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278093c",
   "metadata": {},
   "source": [
    "1. 심장질환을 앓는 사람은 누구일까\n",
    "이번 실습에서는 비전문가인 우리가 심장 질환 환자 데이터를 통해서\n",
    "\n",
    "어떤 사람이 심장질환을 앓는지\n",
    "심장 질환의 주요 요인이 무엇인지\n",
    "를 찾아보면서 도메인 전문성의 중요성을 알아볼 것입니다.\n",
    "\n",
    "도메인 지식이나 비즈니스에 대한 높은 이해도가 데이터를 파악하고 준비하고,\n",
    "나아가 머신러닝 모델의 성능을 향상시키는데 중요한 역할을 한다는 것을 느끼기 위해서\n",
    "심장 질환을 앓는 사람이 누구인지 찾아나갈 것입니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. 심장 질환 (Heart Disease) 개요\n",
    "심장 질환은 수십 년 동안 전 세계인의 주요 사망 원인이었습니다.\n",
    "미국에서는 매 분마다 한 명의 사람이 심장 질환으로 인해 사망하고 있다고 합니다.\n",
    "\n",
    "그동안 많은 의사와 연구자들이 심장질환의 진단 방식을 연구해왔습니다.\n",
    "그리고 그 원인을 밝히기 위해서 많은 전문가들이 노력해 왔습니다.\n",
    "\n",
    "이번 실습에서는 UIC repository에서 제공하는 오픈소스 데이터로\n",
    "실제 심장 질환을 연구하기 위해 만들어진 데이터를 사용할 것입니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcedc0c",
   "metadata": {},
   "source": [
    "데이터 설명\n",
    "변수\t설명\n",
    "age\t나이\n",
    "Age in years\n",
    "sex\t성별\n",
    "1: male(남자), 0: female(여자)\n",
    "chest_pain\t가슴 통증의 유형\n",
    "1: typical angina, 2: atypical angina, 3: non-anginal pain. 4: asymptomatic\n",
    "blood_pressure    \t안정혈압\n",
    "In mm hg on admission to the hospital\n",
    "serum_cholesterol\t혈청 콜레스테롤\n",
    "In mg/dI\n",
    "fasting_blood_sugar\t공복혈당이 > 120 mg/dI인가?\n",
    "1: true, 0: false\n",
    "electro\t안정 심전도 결과\n",
    "0: normal, ,1: having ST-T wave abnormality, 2: showing probable or definite left ventricular hypertrophy by Estes’s criteria\n",
    "max_heart_rate\t최대 심박동수\n",
    "angina\t운동으로 유발된 협심증이 있다\n",
    "1: yes, 0: no\n",
    "st_depression\t휴식 대비 운동 시의 심전도상 ST 분절\n",
    "In mm Hg on admission to the hospital\n",
    "vessels\t주요 vessels의 수\n",
    "0, 1, 2, 3: colored by fluoroscopy\n",
    "slope\tThe slope of the peak exercise ST segment\n",
    "1: up sloping, 2: flat, 3: down sloping\n",
    "thal\tThallium heart scan\n",
    "3: normal, 6: fixed defect, 7: reversible defect\n",
    "diagnosis\t심장질환 진단 결과(Target)\n",
    "0: no disease, 1: heart disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647c994",
   "metadata": {},
   "source": [
    "어떤 요인(feature)이 심장질환과 연관성이 높을까?\n",
    "- 직관과 기존 도메인 지식편\n",
    "이번 실습에서는 현재 도메인에 대해 갖고 있는 여러분의 직관과 기존 도메인 지식만을 이용해서\n",
    "심장질환과 관련성이 가장 높다고 생각되는 요인 3가지를 선택하세요.\n",
    "(예시: age, blood_pressure, slope)\n",
    "\n",
    "\n",
    "\n",
    "Heart Disease Data Set 소개\n",
    "실습에 사용할 심장 질환 데이터는 머신러닝 연구를 위해 제공된 오픈소스 데이터로\n",
    "Cleveland Clinic의 심장질환 연구를 위한 데이터입니다.\n",
    "\n",
    "V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "데이터 특징\n",
    "이 데이터는 본래 76개의 변수/요인(feature)으로 구성되었으나, 그중 13개만이 실제 실험에 사용되었습니다.\n",
    "마지막 변수 diagnosis는 예측하려는 Target입니다.\n",
    "303명의 환자와 비환자를 대상으로 합니다.\n",
    "머신러닝 연구자들이 즐겨 사용하는 데이터입니다.\n",
    "본래 0, 1, 2, 3, 4로 심장질환의 발생과 심각한 정도를 표현했으나 실습을 위해서 발생여부 0과 1로 예측 목표(target)를 변경하였습니다.\n",
    "실습을 위해 13개의 변수에 대해서 사전에 처리된 데이터를 사용합니다.\n",
    "\n",
    "\n",
    "데이터 샘플\n",
    "아래 제공된 50개의 데이터 샘플은 각 요인에 대한 이해를 돕기 위한 자료입니다.\n",
    "\n",
    "age\tsex\tchest_pain\tblood_pressure\tserum_cholestoral\tfasting_blood_sugar\telectro\tmax_heart_rate\tangina\tst_depression\tslope\tvessels\tthal\tdiagnosis\n",
    "63.0\t1.0\t1.0\t145.0\t233.0\t1.0\t2.0\t150.0\t0.0\t2.3\t3.0\t0.0\t6.0\t0\n",
    "67.0\t1.0\t4.0\t160.0\t286.0\t0.0\t2.0\t108.0\t1.0\t1.5\t2.0\t3.0\t3.0\t1\n",
    "67.0\t1.0\t4.0\t120.0\t229.0\t0.0\t2.0\t129.0\t1.0\t2.6\t2.0\t2.0\t7.0\t1\n",
    "37.0\t1.0\t3.0\t130.0\t250.0\t0.0\t0.0\t187.0\t0.0\t3.5\t3.0\t0.0\t3.0\t0\n",
    "41.0\t0.0\t2.0\t130.0\t204.0\t0.0\t2.0\t172.0\t0.0\t1.4\t1.0\t0.0\t3.0\t0\n",
    "63.0\t1.0\t1.0\t145.0\t233.0\t1.0\t2.0\t150.0\t0.0\t2.3\t3.0\t0.0\t6.0\t0\n",
    "67.0\t1.0\t4.0\t160.0\t286.0\t0.0\t2.0\t108.0\t1.0\t1.5\t2.0\t3.0\t3.0\t1\n",
    "67.0\t1.0\t4.0\t120.0\t229.0\t0.0\t2.0\t129.0\t1.0\t2.6\t2.0\t2.0\t7.0\t1\n",
    "37.0\t1.0\t3.0\t130.0\t250.0\t0.0\t0.0\t187.0\t0.0\t3.5\t3.0\t0.0\t3.0\t0\n",
    "41.0\t0.0\t2.0\t130.0\t204.0\t0.0\t2.0\t172.0\t0.0\t1.4\t1.0\t0.0\t3.0\t0\n",
    "56.0\t1.0\t2.0\t120.0\t236.0\t0.0\t0.0\t178.0\t0.0\t0.8\t1.0\t0.0\t3.0\t0\n",
    "62.0\t0.0\t4.0\t140.0\t268.0\t0.0\t2.0\t160.0\t0.0\t3.6\t3.0\t2.0\t3.0\t1\n",
    "57.0\t0.0\t4.0\t120.0\t354.0\t0.0\t0.0\t163.0\t1.0\t0.6\t1.0\t0.0\t3.0\t0\n",
    "63.0\t1.0\t4.0\t130.0\t254.0\t0.0\t2.0\t147.0\t0.0\t1.4\t2.0\t1.0\t7.0\t1\n",
    "53.0\t1.0\t4.0\t140.0\t203.0\t1.0\t2.0\t155.0\t1.0\t3.1\t3.0\t0.0\t7.0\t1\n",
    "57.0\t1.0\t4.0\t140.0\t192.0\t0.0\t0.0\t148.0\t0.0\t0.4\t2.0\t0.0\t6.0\t0\n",
    "56.0\t0.0\t2.0\t140.0\t294.0\t0.0\t2.0\t153.0\t0.0\t1.3\t2.0\t0.0\t3.0\t0\n",
    "56.0\t1.0\t3.0\t130.0\t256.0\t1.0\t2.0\t142.0\t1.0\t0.6\t2.0\t1.0\t6.0\t1\n",
    "44.0\t1.0\t2.0\t120.0\t263.0\t0.0\t0.0\t173.0\t0.0\t0.0\t1.0\t0.0\t7.0\t0\n",
    "52.0\t1.0\t3.0\t172.0\t199.0\t1.0\t0.0\t162.0\t0.0\t0.5\t1.0\t0.0\t7.0\t0\n",
    "57.0\t1.0\t3.0\t150.0\t168.0\t0.0\t0.0\t174.0\t0.0\t1.6\t1.0\t0.0\t3.0\t0\n",
    "48.0\t1.0\t2.0\t110.0\t229.0\t0.0\t0.0\t168.0\t0.0\t1.0\t3.0\t0.0\t7.0\t1\n",
    "54.0\t1.0\t4.0\t140.0\t239.0\t0.0\t0.0\t160.0\t0.0\t1.2\t1.0\t0.0\t3.0\t0\n",
    "48.0\t0.0\t3.0\t130.0\t275.0\t0.0\t0.0\t139.0\t0.0\t0.2\t1.0\t0.0\t3.0\t0\n",
    "49.0\t1.0\t2.0\t130.0\t266.0\t0.0\t0.0\t171.0\t0.0\t0.6\t1.0\t0.0\t3.0\t0\n",
    "64.0\t1.0\t1.0\t110.0\t211.0\t0.0\t2.0\t144.0\t1.0\t1.8\t2.0\t0.0\t3.0\t0\n",
    "58.0\t0.0\t1.0\t150.0\t283.0\t1.0\t2.0\t162.0\t0.0\t1.0\t1.0\t0.0\t3.0\t0\n",
    "58.0\t1.0\t2.0\t120.0\t284.0\t0.0\t2.0\t160.0\t0.0\t1.8\t2.0\t0.0\t3.0\t1\n",
    "58.0\t1.0\t3.0\t132.0\t224.0\t0.0\t2.0\t173.0\t0.0\t3.2\t1.0\t2.0\t7.0\t1\n",
    "60.0\t1.0\t4.0\t130.0\t206.0\t0.0\t2.0\t132.0\t1.0\t2.4\t2.0\t2.0\t7.0\t1\n",
    "50.0\t0.0\t3.0\t120.0\t219.0\t0.0\t0.0\t158.0\t0.0\t1.6\t2.0\t0.0\t3.0\t0\n",
    "58.0\t0.0\t3.0\t120.0\t340.0\t0.0\t0.0\t172.0\t0.0\t0.0\t1.0\t0.0\t3.0\t0\n",
    "66.0\t0.0\t1.0\t150.0\t226.0\t0.0\t0.0\t114.0\t0.0\t2.6\t3.0\t0.0\t3.0\t0\n",
    "43.0\t1.0\t4.0\t150.0\t247.0\t0.0\t0.0\t171.0\t0.0\t1.5\t1.0\t0.0\t3.0\t0\n",
    "40.0\t1.0\t4.0\t110.0\t167.0\t0.0\t2.0\t114.0\t1.0\t2.0\t2.0\t0.0\t7.0\t1\n",
    "69.0\t0.0\t1.0\t140.0\t239.0\t0.0\t0.0\t151.0\t0.0\t1.8\t1.0\t2.0\t3.0\t0\n",
    "60.0\t1.0\t4.0\t117.0\t230.0\t1.0\t0.0\t160.0\t1.0\t1.4\t1.0\t2.0\t7.0\t1\n",
    "64.0\t1.0\t3.0\t140.0\t335.0\t0.0\t0.0\t158.0\t0.0\t0.0\t1.0\t0.0\t3.0\t1\n",
    "59.0\t1.0\t4.0\t135.0\t234.0\t0.0\t0.0\t161.0\t0.0\t0.5\t2.0\t0.0\t7.0\t0\n",
    "44.0\t1.0\t3.0\t130.0\t233.0\t0.0\t0.0\t179.0\t1.0\t0.4\t1.0\t0.0\t3.0\t0\n",
    "42.0\t1.0\t4.0\t140.0\t226.0\t0.0\t0.0\t178.0\t0.0\t0.0\t1.0\t0.0\t3.0\t0\n",
    "43.0\t1.0\t4.0\t120.0\t177.0\t0.0\t2.0\t120.0\t1.0\t2.5\t2.0\t0.0\t7.0\t1\n",
    "57.0\t1.0\t4.0\t150.0\t276.0\t0.0\t2.0\t112.0\t1.0\t0.6\t2.0\t1.0\t6.0\t1\n",
    "55.0\t1.0\t4.0\t132.0\t353.0\t0.0\t0.0\t132.0\t1.0\t1.2\t2.0\t1.0\t7.0\t1\n",
    "61.0\t1.0\t3.0\t150.0\t243.0\t1.0\t0.0\t137.0\t1.0\t1.0\t2.0\t0.0\t3.0\t0\n",
    "65.0\t0.0\t4.0\t150.0\t225.0\t0.0\t2.0\t114.0\t0.0\t1.0\t2.0\t3.0\t7.0\t1\n",
    "40.0\t1.0\t1.0\t140.0\t199.0\t0.0\t0.0\t178.0\t1.0\t1.4\t1.0\t0.0\t7.0\t0\n",
    "71.0\t0.0\t2.0\t160.0\t302.0\t0.0\t0.0\t162.0\t0.0\t0.4\t1.0\t2.0\t3.0\t0\n",
    "59.0\t1.0\t3.0\t150.0\t212.0\t1.0\t0.0\t157.0\t0.0\t1.6\t1.0\t0.0\t3.0\t0\n",
    "61.0\t0.0\t4.0\t130.0\t330.0\t0.0\t2.0\t169.0\t0.0\t0.0\t1.0\t0.0\t3.0\t1\n",
    "58.0\t1.0\t3.0\t112.0\t230.0\t0.0\t2.0\t165.0\t0.0\t2.5\t2.0\t1.0\t7.0\t1\n",
    "51.0\t1.0\t3.0\t110.0\t175.0\t0.0\t0.0\t123.0\t0.0\t0.6\t1.0\t0.0\t3.0\t0\n",
    "50.0\t1.0\t4.0\t150.0\t243.0\t0.0\t2.0\t128.0\t0.0\t2.6\t2.0\t0.0\t7.0\t1\n",
    "65.0\t0.0\t3.0\t140.0\t417.0\t1.0\t2.0\t157.0\t0.0\t0.8\t1.0\t1.0\t3.0\t0\n",
    "53.0\t1.0\t3.0\t130.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70d971",
   "metadata": {},
   "source": [
    "선택한 3가지 요인의 실제 연관성 파악하기\n",
    "앞 페이지에서 실제 Cleveland Clinic의 심장질환 데이터를 소개하고, 현재 여러분이 가지고 있는 직관과 기존 도메인 지식만을 이용해서 어떤 요인이 심장질환과 연관성이 높을지를 분석했습니다.\n",
    "\n",
    "이제 선택한 3개의 요인이 실제 머신러닝 알고리즘을 통해 생성된 모델에 들어갔을 때 어떠한 성능이 나오는지 확인해보겠습니다.\n",
    "\n",
    "만약 선택한 3개의 요인이 실제로 심장질환과 연관성이 높다면 머신러닝 모델의 성능(정확도)가 높게 나올 것입니다.\n",
    "\n",
    "선택할 변수 설명\n",
    "변수\t설명\n",
    "age\t나이\n",
    "sex\t성별\n",
    "chest_pain\t가슴 통증의 유형\n",
    "blood_pressure\t안정혈압\n",
    "serum_cholesterol\t혈청 콜레스테롤\n",
    "fasting_blood_sugar\t공복혈당\n",
    "electro\t안정 심전도 결과\n",
    "max_heart_rate\t최대 심박동수\n",
    "angina\t운동으로 유발된 협심증\n",
    "st_depression\t심전도상 ST 분절\n",
    "vessels\t주요 vessels의 수\n",
    "slope\tThe slope of the peak exercise ST segment\n",
    "thal\tThallium heart scan\n",
    "\n",
    "지시사항\n",
    "머신러닝에서는 변수나 요인을 feature 라고 부릅니다. 앞 페이지에서 선택한 3개의feature의 이름을 아래 예시를 참고하여 오른쪽 실습 화면에 입력해주세요.\n",
    "\n",
    "feature의 이름을 입력할 때에는 예시와 같이 따옴표 '로 묶어서 표시해야합니다.\n",
    "(예시)\n",
    "\n",
    "features = ['serum_cholesterol', 'fasting_blood_sugar', 'electro']\n",
    "Copy\n",
    "입력을 완료하고 왼쪽 아래 실행 버튼을 눌러 해당 feature를 이용해서 만든 머신러닝의 성능(정확도) 결과를 확인하고 제출해보세요. 나올 수 있는 모델의 최고 정확도는 84.45% 입니다.\n",
    "\n",
    "(예시)\n",
    "\n",
    "Accuracy : 64.36%\n",
    "Copy\n",
    "선택한 요인의 정확도는 위와 같이 나타납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fdeecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heart_disease.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "columns = ['age','sex','chest_pain','blood_pressure','serum_cholesterol','fasting_blood_sugar',\n",
    "               'electro','max_heart_rate','angina','st_depression','slope','vessels','thal','diagnosis']\n",
    "categorical_columns = ['sex', 'chest_pain', 'fasting_blood_sugar', 'electro', 'angina', 'slope', 'vessels']\n",
    "numeric_columns = ['age', 'blood_pressure', 'serum_cholestoral', 'max_heart_rate', 'st_depression']\n",
    "target = ['diagnosis']\n",
    "columns_type = {\n",
    "    'age': np.float,\n",
    "    'sex':np.object,\n",
    "    'chest_pain':np.object,\n",
    "    'blood_pressure':np.float,\n",
    "    'serum_cholestoral':np.float,\n",
    "    'fasting_blood_sugar':np.object,\n",
    "    'electrocardiographic':np.object,\n",
    "    'max_heart_rate':np.float,\n",
    "    'induced_angina':np.object,\n",
    "    'ST_depression': np.float,\n",
    "    'slope':np.object,\n",
    "    'vessels':np.object,\n",
    "    'thal':np.object,\n",
    "    'diagnosis':np.int\n",
    "}\n",
    "\n",
    "def load_dataset():\n",
    "\tdata = pd.read_csv('./data/processed.cleveland.data', dtype=columns_type, names=columns)\n",
    "\tdata['diagnosis'].replace(to_replace=[1,2,3,4], value=1, inplace=True)\n",
    "\t#heart.replace(to_replace='?', value=np.nan, inplace=True)\n",
    "\tfor c in data.columns[:-1]:\n",
    "\t\tdata[c] = data[c].apply(lambda x: data[data[c]!='?'][c].astype(float).mean() if x == '?' else x)\n",
    "\tdata.dropna(axis=0, inplace=True)\n",
    "\treturn data #heart\n",
    "\n",
    "def cleansing_categorical(indices_categorical_columns):\n",
    "    categorical_pipline =  Pipeline(steps=[\n",
    "                    ('select', FunctionTransformer(lambda data: data[:, indices_categorical_columns])),\n",
    "                    ('onehot', OneHotEncoder(sparse=False))\n",
    "                ])\n",
    "    return categorical_pipline\n",
    "\n",
    "def cleansing_numeric(indices_numeric_columns):\n",
    "    numeric_pipline = Pipeline(steps=[\n",
    "                    ('select', FunctionTransformer(lambda data: data[:, indices_numeric_columns])),\n",
    "                    ('scale', StandardScaler())\n",
    "                ])\n",
    "    return numeric_pipline\n",
    "\n",
    "def create_estimator(df, model):\n",
    "    indices_categorical_columns = df.dtypes == np.object\n",
    "    indices_numeric_columns = df.dtypes != np.object\n",
    "    if indices_categorical_columns.sum() != 0 and indices_numeric_columns.sum() != 0:\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('cleansing', FeatureUnion(transformer_list=[\n",
    "                ('categorical', cleansing_categorical(indices_categorical_columns)),\n",
    "                ('numeric', cleansing_numeric(indices_numeric_columns))\n",
    "            ])),\n",
    "            ('modeling', model)\n",
    "        ])\n",
    "    elif indices_categorical_columns.sum() !=0 and indices_numeric_columns.sum() == 0:\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('cleansing', FeatureUnion(transformer_list=[\n",
    "                ('categorical', cleansing_categorical(indices_categorical_columns))\n",
    "            ])),\n",
    "            ('modeling', model)\n",
    "        ])\n",
    "    elif indices_categorical_columns.sum() ==0 and indices_numeric_columns.sum() != 0:\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('cleansing', FeatureUnion(transformer_list=[\n",
    "                ('numeric', cleansing_numeric(indices_numeric_columns))\n",
    "            ])),\n",
    "            ('modeling', model)\n",
    "        ])\n",
    "    else:\n",
    "        return None\n",
    "    return estimator\n",
    "\n",
    "def scoring_columns(data, using_columns):\n",
    "    data_x, data_y = data.loc[:, using_columns].copy(), data.iloc[:, -1].copy()\n",
    "    model = LogisticRegression()\n",
    "    estimator = create_estimator(data_x, model)\n",
    "    score = cross_val_score(estimator=estimator, X=data_x, y=data_y, cv=5).mean()\n",
    "    return score\n",
    "\n",
    "def is_in_features(features):\n",
    "\tcolumns = ['age','sex','chest_pain','blood_pressure','serum_cholesterol','fasting_blood_sugar',\n",
    "               'electro','max_heart_rate','angina','st_depression','slope','vessels','thal','diagnosis']\n",
    "\treturn set(features).issubset(columns)\n",
    "\n",
    "def check_3_features(features):\n",
    "\tin_features = is_in_features(features)\n",
    "\tif not in_features:\n",
    "\t\tprint('Error!! 요인(feature)의 이름을 올바르게 작성했는지 확인해주세요. 철자가 틀렸을 수도 있습니다.')\n",
    "\t\treturn None\n",
    "\tfeatures = list(set(features))\n",
    "\tif len(features) != 3:\n",
    "\t\tprint('Error!! 선택해야 하는 요인의 수는 3개입니다.')\n",
    "\t\treturn None\n",
    "\theart = load_dataset()\n",
    "\tscore = scoring_columns(heart, features)\n",
    "\tprint(\"선택한 요인은 {} 입니다.\".format(features))\n",
    "\tprint(\"선택한 요인으로 생성한 머신러닝 모델의 심장질환에 대한 분류 예측 정확도는 다음과 같습니다.\")\n",
    "\tprint(\"Accuracy : {0:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc9d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heart_disease import *\n",
    "\n",
    "\n",
    "def result_of_heart_disease_prediction():\n",
    "    # 선택한 3개의 요인이 실제 심장질환에 얼마나 관련성이 있는지 확인합니다.\n",
    "    # Example: features = ['age', 'sex', 'blood_pressure']\n",
    "    features = ['chest_pain', 'vessels', 'thal']\n",
    "    check_3_features(features)\n",
    "    \n",
    "    return features \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result_of_heart_disease_prediction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3557a43",
   "metadata": {},
   "source": [
    "데이터 설명\n",
    "변수\t설명\n",
    "age\t나이\n",
    "Age in years\n",
    "sex\t성별\n",
    "1: male(남자), 0: female(여자)\n",
    "chest_pain\t가슴 통증의 유형\n",
    "1: typical angina, 2: atypical angina, 3: non-anginal pain. Vlaue4: asymptomatic\n",
    "blood_pressure\t안정혈압\n",
    "In mm hg on admission to the hospital\n",
    "serum_cholesterol\t혈청 콜레스테롤\n",
    "In mg/dI\n",
    "fasting_blood_sugar\t공복혈당이 > 120 mg/dI인가?\n",
    "1: true, 0: false\n",
    "electro\t안정 심전도 결과\n",
    "0: normal, ,1: having ST-T wave abnormality, 2: showing probable or definite left ventricular hypertrophy by Estes’s criteria\n",
    "max_heart_rate\t최대 심박동수\n",
    "angina\t운동으로 유발된 협심증이 있다\n",
    "1: yes, 0: no\n",
    "st_depression\t휴식 대비 운동 시의 심전도상 ST 분절\n",
    "In mm Hg on admission to the hospital\n",
    "vessels\t주요 vessels의 수\n",
    "0, 1, 2, 3: colored by fluoroscopy\n",
    "slope\tThe slope of the peak exercise ST segment\n",
    "1: up sloping, 2: flat, 3: down sloping\n",
    "thal\tThallium heart scan\n",
    "3: normal, 6: fixed defect, 7: reversible defect\n",
    "diagnosis\t심장질환 진단 결과(Target)\n",
    "0: no disease, 1: heart disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9accd96",
   "metadata": {},
   "source": [
    "어떤 요인(feature)이 심장질환과 연관성이 높을까?\n",
    "- 데이터 과학자 편\n",
    "도메인 전문성이 상당히 중요했다…\n",
    "원래의 심장 질환 데이터는 76개의 요인을 가지고 있었습니다.\n",
    "\n",
    "연구자들이 먼저 어떤 요인/변수가 중요한지 분석 과정을 거쳤고,\n",
    "최종적으로 사용한 요인은 앞서 소개한 13개의 요인입니다.\n",
    "\n",
    "앞선 실습에서 여러분이 선택한 3가지 요인의 정확도는 얼마나 되었나요?\n",
    "최대 정확도에 도달했다면 그 기준과 근거는 무엇이었나요?\n",
    "\n",
    "직관적으로 문제를 이해하고 핵심 요인을 찾을 때는\n",
    "비즈니스와 도메인에 대한 이해와 지식이 중요한 역할을 합니다.\n",
    "\n",
    "따라서, 데이터가 중심인 데이터 과학에서도 도메인에 대한 지식과 이해는 중요합니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "도메인을 모른다면 데이터 과학자스럽게 해보기\n",
    "중요한 요인을 찾아가는 과정에는 데이터 과학적 방법이 많은 도움이 됩니다.\n",
    "\n",
    "이번에는 첫 수업에서 만들었던 규칙을 만들어도 좋고!\n",
    "인터넷 검색을 통해 도메인을 공부해도 좋습니다!\n",
    "또한, 아래의 13개 요인을 모두 사용해도 좋고!\n",
    "혹은 일부 요인만 사용해도 좋습니다!\n",
    "\n",
    "\n",
    "이번 실습에서는 할 수 있는 방법을 모두 동원해서\n",
    "최고의 정확도를 만들어낼 수 있는 핵심 요인들을 자유롭게 찾아보겠습니다.\n",
    "\n",
    "\n",
    "\n",
    "데이터 샘플\n",
    "age\tsex\tchest_pain\tblood_pressure\tserum_cholestoral\tfasting_blood_sugar\telectro\tmax_heart_rate\tangina\tst_depression\tslope\tvessels\tthal\tdiagnosis\n",
    "63.0\t1.0\t1.0\t145.0\t233.0\t1.0\t2.0\t150.0\t0.0\t2.3\t3.0\t0.0\t6.0\t0\n",
    "67.0\t1.0\t4.0\t160.0\t286.0\t0.0\t2.0\t108.0\t1.0\t1.5\t2.0\t3.0\t3.0\t1\n",
    "67.0\t1.0\t4.0\t120.0\t229.0\t0.0\t2.0\t129.0\t1.0\t2.6\t2.0\t2.0\t7.0\t1\n",
    "37.0\t1.0\t3.0\t130.0\t250.0\t0.0\t0.0\t187.0\t0.0\t3.5\t3.0\t0.0\t3.0\t0\n",
    "41.0\t0.0\t2.0\t130.0\t204.0\t0.0\t2.0\t172.0\t0.0\t1.4\t1.0\t0.0\t3.0\t0\n",
    "63.0\t1.0\t1.0\t145.0\t233.0\t1.0\t2.0\t150.0\t0.0\t2.3\t3.0\t0.0\t6.0\t0\n",
    "67.0\t1.0\t4.0\t160.0\t286.0\t0.0\t2.0\t108.0\t1.0\t1.5\t2.0\t3.0\t3.0\t1\n",
    "67.0\t1.0\t4.0\t120.0\t229.0\t0.0\t2.0\t129.0\t1.0\t2.6\t2.0\t2.0\t7.0\t1\n",
    "37.0\t1.0\t3.0\t130.0\t250.0\t0.0\t0.0\t187.0\t0.0\t3.5\t3.0\t0.0\t3.0\t0\n",
    "41.0\t0.0\t2.0\t130.0\t204.0\t0.0\t2.0\t172.0\t0.0\t1.4\t1.0\t0.0\t3.0\t0\n",
    "56.0\t1.0\t2.0\t120.0\t236.0\t0.0\t0.0\t178.0\t0.0\t0.8\t1.0\t0.0\t3.0\t0\n",
    "62.0\t0.0\t4.0\t140.0\t268.0\t0.0\t2.0\t160.0\t0.0\t3.6\t3.0\t2.0\t3.0\t1\n",
    "57.0\t0.0\t4.0\t120.0\t354.0\t0.0\t0.0\t163.0\t1.0\t0.6\t1.0\t0.0\t3.0\t0\n",
    "63.0\t1.0\t4.0\t130.0\t254.0\t0.0\t2.0\t147.0\t0.0\t1.4\t2.0\t1.0\t7.0\t1\n",
    "53.0\t1.0\t4.0\t140.0\t203.0\t1.0\t2.0\t155.0\t1.0\t3.1\t3.0\t0.0\t7.0\t1\n",
    "57.0\t1.0\t4.0\t140.0\t192.0\t0.0\t0.0\t148.0\t0.0\t0.4\t2.0\t0.0\t6.0\t0\n",
    "56.0\t0.0\t2.0\t140.0\t294.0\t0.0\t2.0\t153.0\t0.0\t1.3\t2.0\t0.0\t3.0\t0\n",
    "56.0\t1.0\t3.0\t130.0\t256.0\t1.0\t2.0\t142.0\t1.0\t0.6\t2.0\t1.0\t6.0\t1\n",
    "44.0\t1.0\t2.0\t120.0\t263.0\t0.0\t0.0\t173.0\t0.0\t0.0\t1.0\t0.0\t7.0\t0\n",
    "52.0\t1.0\t3.0\t172.0\t199.0\t1.0\t0.0\t162.0\t0.0\t0.5\t1.0\t0.0\t7.0\t0\n",
    "57.0\t1.0\t3.0\t150.0\t168.0\t0.0\t0.0\t174.0\t0.0\t1.6\t1.0\t0.0\t3.0\t0\n",
    "48.0\t1.0\t2.0\t110.0\t229.0\t0.0\t0.0\t168.0\t0.0\t1.0\t3.0\t0.0\t7.0\t1\n",
    "54.0\t1.0\t4.0\t140.0\t239.0\t0.0\t0.0\t160.0\t0.0\t1.2\t1.0\t0.0\t3.0\t0\n",
    "48.0\t0.0\t3.0\t130.0\t275.0\t0.0\t0.0\t139.0\t0.0\t0.2\t1.0\t0.0\t3.0\t0\n",
    "49.0\t1.0\t2.0\t130.0\t266.0\t0.0\t0.0\t171.0\t0.0\t0.6\t1.0\t0.0\t3.0\t0\n",
    "64.0\t1.0\t1.0\t110.0\t211.0\t0.0\t2.0\t144.0\t1.0\t1.8\t2.0\t0.0\t3.0\t0\n",
    "58.0\t0.0\t1.0\t150.0\t283.0\t1.0\t2.0\t162.0\t0.0\t1.0\t1.0\t0.0\t3.0\t0\n",
    "58.0\t1.0\t2.0\t120.0\t284.0\t0.0\t2.0\t160.0\t0.0\t1.8\t2.0\t0.0\t3.0\t1\n",
    "58.0\t1.0\t3.0\t132.0\t224.0\t0.0\t2.0\t173.0\t0.0\t3.2\t1.0\t2.0\t7.0\t1\n",
    "60.0\t1.0\t4.0\t130.0\t206.0\t0.0\t2.0\t132.0\t1.0\t2.4\t2.0\t2.0\t7.0\t1\n",
    "50.0\t0.0\t3.0\t120.0\t219.0\t0.0\t0.0\t158.0\t0.0\t1.6\t2.0\t0.0\t3.0\t0\n",
    "58.0\t0.0\t3.0\t120.0\t340.0\t0.0\t0.0\t172.0\t0.0\t0.0\t1.0\t0.0\t3.0\t0\n",
    "66.0\t0.0\t1.0\t150.0\t226.0\t0.0\t0.0\t114.0\t0.0\t2.6\t3.0\t0.0\t3.0\t0\n",
    "43.0\t1.0\t4.0\t150.0\t247.0\t0.0\t0.0\t171.0\t0.0\t1.5\t1.0\t0.0\t3.0\t0\n",
    "40.0\t1.0\t4.0\t110.0\t167.0\t0.0\t2.0\t114.0\t1.0\t2.0\t2.0\t0.0\t7.0\t1\n",
    "69.0\t0.0\t1.0\t140.0\t239.0\t0.0\t0.0\t151.0\t0.0\t1.8\t1.0\t2.0\t3.0\t0\n",
    "60.0\t1.0\t4.0\t117.0\t230.0\t1.0\t0.0\t160.0\t1.0\t1.4\t1.0\t2.0\t7.0\t1\n",
    "64.0\t1.0\t3.0\t140.0\t335.0\t0.0\t0.0\t158.0\t0.0\t0.0\t1.0\t0.0\t3.0\t1\n",
    "59.0\t1.0\t4.0\t135.0\t234.0\t0.0\t0.0\t161.0\t0.0\t0.5\t2.0\t0.0\t7.0\t0\n",
    "44.0\t1.0\t3.0\t130.0\t233.0\t0.0\t0.0\t179.0\t1.0\t0.4\t1.0\t0.0\t3.0\t0\n",
    "42.0\t1.0\t4.0\t140.0\t226.0\t0.0\t0.0\t178.0\t0.0\t0.0\t1.0\t0.0\t3.0\t0\n",
    "43.0\t1.0\t4.0\t120.0\t177.0\t0.0\t2.0\t120.0\t1.0\t2.5\t2.0\t0.0\t7.0\t1\n",
    "57.0\t1.0\t4.0\t150.0\t276.0\t0.0\t2.0\t112.0\t1.0\t0.6\t2.0\t1.0\t6.0\t1\n",
    "55.0\t1.0\t4.0\t132.0\t353.0\t0.0\t0.0\t132.0\t1.0\t1.2\t2.0\t1.0\t7.0\t1\n",
    "61.0\t1.0\t3.0\t150.0\t243.0\t1.0\t0.0\t137.0\t1.0\t1.0\t2.0\t0.0\t3.0\t0\n",
    "65.0\t0.0\t4.0\t150.0\t225.0\t0.0\t2.0\t114.0\t0.0\t1.0\t2.0\t3.0\t7.0\t1\n",
    "40.0\t1.0\t1.0\t140.0\t199.0\t0.0\t0.0\t178.0\t1.0\t1.4\t1.0\t0.0\t7.0\t0\n",
    "71.0\t0.0\t2.0\t160.0\t302.0\t0.0\t0.0\t162.0\t0.0\t0.4\t1.0\t2.0\t3.0\t0\n",
    "59.0\t1.0\t3.0\t150.0\t212.0\t1.0\t0.0\t157.0\t0.0\t1.6\t1.0\t0.0\t3.0\t0\n",
    "61.0\t0.0\t4.0\t130.0\t330.0\t0.0\t2.0\t169.0\t0.0\t0.0\t1.0\t0.0\t3.0\t1\n",
    "58.0\t1.0\t3.0\t112.0\t230.0\t0.0\t2.0\t165.0\t0.0\t2.5\t2.0\t1.0\t7.0\t1\n",
    "51.0\t1.0\t3.0\t110.0\t175.0\t0.0\t0.0\t123.0\t0.0\t0.6\t1.0\t0.0\t3.0\t0\n",
    "50.0\t1.0\t4.0\t150.0\t243.0\t0.0\t2.0\t128.0\t0.0\t2.6\t2.0\t0.0\t7.0\t1\n",
    "65.0\t0.0\t3.0\t140.0\t417.0\t1.0\t2.0\t157.0\t0.0\t0.8\t1.0\t1.0\t3.0\t0\n",
    "53.0\t1.0\t3.0\t130.0\t197.0\t1.0\t2.0\t152.0\t0.0\t1.2\t3.0\t0.0\t3.0\t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d888d",
   "metadata": {},
   "source": [
    "최고의 요인 조합으로, 최고의 정확도에 도전!\n",
    "이번 실습을 통해 여러 변수들을 조합해보며 최고 정확도인 86% 를 목표로 하여 모델의 성능을 높여보겠습니다.\n",
    "\n",
    "지난 실습에서 직관과 기존 도메인 지식만을 사용해 요인을 선택했을 때, 낮게는 50%대의 정확도를 보이는 모델을 만들었을 것입니다.\n",
    "\n",
    "\n",
    "\n",
    "그 이유는 무엇일까요?\n",
    "요인을 3개 밖에 사용하지 못했기 때문일까요?\n",
    "\n",
    "\n",
    "모든 요인의 조합을 고려한다고 해도 이번 실습에서 나올 수 있는 최고 정확도는 86.44% 입니다.\n",
    "\n",
    "앞서 만든 규칙 혹은 공부를 통해 익힌 도메인 지식을 활용하여 아래 13개의 변수 중에서 심장 질환과 연관성이 높은 핵심 요인들을 개수에 상관없이 자유롭게 선택하고 입력하여 최고 정확도에 도전해보세요.\n",
    "\n",
    "선택할 변수 설명\n",
    "변수\t설명\n",
    "age\t나이\n",
    "sex\t성별\n",
    "chest_pain\t가슴 통증의 유형\n",
    "blood_pressure\t안정혈압\n",
    "serum_cholesterol\t혈청 콜레스테롤\n",
    "fasting_blood_sugar\t공복혈당\n",
    "electro\t안정 심전도 결과\n",
    "max_heart_rate\t최대 심박동수\n",
    "angina\t운동으로 유발된 협심증\n",
    "st_depression\t심전도상 ST 분절\n",
    "vessels\t주요 vessels의 수\n",
    "slope\tThe slope of the peak exercise ST segment\n",
    "thal\tThallium heart scan\n",
    "\n",
    "지시사항\n",
    "오른쪽 실습 화면에 원하는만큼 개수에 상관없이 최대 13개의 feature를 입력해주세요.\n",
    "\n",
    "(예시)\n",
    "\n",
    "features = ['age', 'sex', 'serum_cholesterol', 'fasting_blood_sugar', 'electro']\n",
    "Copy\n",
    "입력을 완료하고 왼쪽 아래 실행 버튼을 눌러 해당 요인들을 이용해서 만든 머신러닝의 성능 결과를 확인해보세요.\n",
    "\n",
    "(예시)\n",
    "\n",
    "Accuracy : 64.36%\n",
    "Copy\n",
    "다양한 요인들을 조합해보며 모델의 성능을 확인하고, 최고 정확도인 86% 를 목표로 하여 최대한 모델의 성능을 높여본 후 제출 버튼을 눌러보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1202b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "columns = ['age','sex','chest_pain','blood_pressure','serum_cholesterol','fasting_blood_sugar',\n",
    "               'electro','max_heart_rate','angina','st_depression','slope','vessels','thal','diagnosis']\n",
    "categorical_columns = ['sex', 'chest_pain', 'fasting_blood_sugar', 'electro', 'angina', 'slope', 'vessels']\n",
    "numeric_columns = ['age', 'blood_pressure', 'serum_cholestoral', 'max_heart_rate', 'st_depression']\n",
    "target = ['diagnosis']\n",
    "columns_type = {\n",
    "    'age': np.float,\n",
    "    'sex':np.object,\n",
    "    'chest_pain':np.object,\n",
    "    'blood_pressure':np.float,\n",
    "    'serum_cholestoral':np.float,\n",
    "    'fasting_blood_sugar':np.object,\n",
    "    'electrocardiographic':np.object,\n",
    "    'max_heart_rate':np.float,\n",
    "    'induced_angina':np.object,\n",
    "    'ST_depression': np.float,\n",
    "    'slope':np.object,\n",
    "    'vessels':np.object,\n",
    "    'thal':np.object,\n",
    "    'diagnosis':np.int\n",
    "}\n",
    "\n",
    "def load_dataset():\n",
    "\tdata = pd.read_csv('./data/processed.cleveland.data', dtype=columns_type, names=columns)\n",
    "\tdata['diagnosis'].replace(to_replace=[1,2,3,4], value=1, inplace=True)\n",
    "\t#heart.replace(to_replace='?', value=np.nan, inplace=True)\n",
    "\tfor c in data.columns[:-1]:\n",
    "\t\tdata[c] = data[c].apply(lambda x: data[data[c]!='?'][c].astype(float).mean() if x == '?' else x)\n",
    "\tdata.dropna(axis=0, inplace=True)\n",
    "\treturn data #heart\n",
    "\n",
    "def cleansing_categorical(indices_categorical_columns):\n",
    "    categorical_pipline =  Pipeline(steps=[\n",
    "                    ('select', FunctionTransformer(lambda data: data[:, indices_categorical_columns])),\n",
    "                    ('onehot', OneHotEncoder(sparse=False))\n",
    "                ])\n",
    "    return categorical_pipline\n",
    "\n",
    "def cleansing_numeric(indices_numeric_columns):\n",
    "    numeric_pipline = Pipeline(steps=[\n",
    "                    ('select', FunctionTransformer(lambda data: data[:, indices_numeric_columns])),\n",
    "                    ('scale', StandardScaler())\n",
    "                ])\n",
    "    return numeric_pipline\n",
    "\n",
    "def create_estimator(df, model):\n",
    "    indices_categorical_columns = df.dtypes == np.object\n",
    "    indices_numeric_columns = df.dtypes != np.object\n",
    "    if indices_categorical_columns.sum() != 0 and indices_numeric_columns.sum() != 0:\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('cleansing', FeatureUnion(transformer_list=[\n",
    "                ('categorical', cleansing_categorical(indices_categorical_columns)),\n",
    "                ('numeric', cleansing_numeric(indices_numeric_columns))\n",
    "            ])),\n",
    "            ('modeling', model)\n",
    "        ])\n",
    "    elif indices_categorical_columns.sum() !=0 and indices_numeric_columns.sum() == 0:\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('cleansing', FeatureUnion(transformer_list=[\n",
    "                ('categorical', cleansing_categorical(indices_categorical_columns))\n",
    "            ])),\n",
    "            ('modeling', model)\n",
    "        ])\n",
    "    elif indices_categorical_columns.sum() ==0 and indices_numeric_columns.sum() != 0:\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('cleansing', FeatureUnion(transformer_list=[\n",
    "                ('numeric', cleansing_numeric(indices_numeric_columns))\n",
    "            ])),\n",
    "            ('modeling', model)\n",
    "        ])\n",
    "    else:\n",
    "        return None\n",
    "    return estimator\n",
    "\n",
    "def scoring_columns(data, using_columns):\n",
    "    data_x, data_y = data.loc[:, using_columns].copy(), data.iloc[:, -1].copy()\n",
    "    model = LogisticRegression()\n",
    "    estimator = create_estimator(data_x, model)\n",
    "    score = cross_val_score(estimator=estimator, X=data_x, y=data_y, cv=5).mean()\n",
    "    return score\n",
    "\n",
    "def is_in_features(features):\n",
    "    columns = ['age','sex','chest_pain','blood_pressure','serum_cholesterol','fasting_blood_sugar',\n",
    "               'electro','max_heart_rate','angina','st_depression','slope','vessels','thal','diagnosis']\n",
    "    return set(features).issubset(columns)\n",
    "\n",
    "def check_features(features):\n",
    "    in_features = is_in_features(features)\n",
    "    if not in_features:\n",
    "        print('Error!! 요인(feature)의 이름을 올바르게 작성했는지 확인해주세요. 철자가 틀렸을 수도 있습니다.')\n",
    "        return None\n",
    "    if 'diagnosis' in features:\n",
    "        print('Error!! `diagnosis`는 우리가 예측하고자 하는 목표입니다. Input에서 제외하고 다시 실행해주세요.')\n",
    "        return None\n",
    "    features = list(set(features))\n",
    "    if len(features) > 13:\n",
    "        print('Error!! 13개 이하의 요인을 입력해주세요.')\n",
    "        return None\n",
    "    if len(features) < 1:\n",
    "        print('Error!! 1개 이상의 요인을 입력해주세요.')\n",
    "        return None\n",
    "    heart = load_dataset()\n",
    "    score = scoring_columns(heart, features)\n",
    "    print(\"선택한 요인은 {} 입니다.\".format(features))\n",
    "    print(\"선택한 요인으로 생성한 머신러닝 모델의 심장질환에 대한 분류 예측 정확도는 다음과 같습니다.\")\n",
    "    print(\"Accuracy : {0:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d093dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heart_disease import *\n",
    "\n",
    "\n",
    "def result_of_heart_disease_prediction():\n",
    "    # 심장질환과 연관성이 높은 핵심 요인을 자유롭게 입력하여 정확도를 높여주세요\n",
    "    # Example: features = ['age', 'sex', 'blood_pressure', 'serum_cholesterol']\n",
    "    features = ['sex', 'chest_pain', 'vessels', 'max_heart_rate', 'thal']\n",
    "    check_features(features)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result_of_heart_disease_prediction()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
