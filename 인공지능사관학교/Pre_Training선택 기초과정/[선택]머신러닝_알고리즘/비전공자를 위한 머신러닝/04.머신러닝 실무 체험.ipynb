{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eece781",
   "metadata": {},
   "source": [
    "수업 목표\n",
    "\n",
    "1. 머신러닝 업무를 위한 문제파악 및 문제정의 과정을 이해합니다.\n",
    "\n",
    "2. 머신러닝 업무를 위한 모델 구축 및 평가 과정을 이해합니다.\n",
    "\n",
    "3. 비즈니스 관점에서 위의 과정들을 이해합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f7012",
   "metadata": {},
   "source": [
    "실습 목표\n",
    "\n",
    "1. Data Preprocessing과 Feature Engineering을 복습합니다.\n",
    "\n",
    "2. 머신러닝 문제에 따라 알맞은 모델 알고리즘을 선택합니다.\n",
    "\n",
    "3. 머신러닝 관점과 비즈니스 관점으로\n",
    "   모델의 예측 성능과 기대손익을 분석합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ab12f",
   "metadata": {},
   "source": [
    "목 차\n",
    "\n",
    "1. 머신러닝 업무 익히기\n",
    "\n",
    "2. 타겟 마켓딩을 위한 머신러닝 업부"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87606e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0eeaf94c",
   "metadata": {},
   "source": [
    "1. 머신러닝 업무 익히기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5066aedf",
   "metadata": {},
   "source": [
    "머신러닝 업무 익히기(1)\n",
    "문제 정의, 머신러닝 학습 유형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4cc7e0",
   "metadata": {},
   "source": [
    "어신러닝 엄무 리뷰\n",
    "\n",
    "<데이터 과학의 목표>\n",
    "\n",
    "Decision Making(의사결정 지원)\n",
    "\n",
    "\n",
    "Monetization(경제적 이익 창출)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f63f657",
   "metadata": {},
   "source": [
    "<머신러닝의 목표>\n",
    "\n",
    "Prediction & aPattern Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b027459c",
   "metadata": {},
   "source": [
    "머신 러닝 업무 프로세스\n",
    "\n",
    "1. 문제 파악 문제 정의\n",
    "\n",
    "2. 데이터 준비\n",
    "\n",
    "3. 모덱 구축 & 평가\n",
    "\n",
    "4. 결과 공유\n",
    "\n",
    "5. 모니터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a4c68",
   "metadata": {},
   "source": [
    "Define the Problem\n",
    "\n",
    "머신러닝 프로젝트를 시작할 때\n",
    "해결해야 하는 비즈니스 문제를 명확하게 먼저 정의\n",
    "\n",
    "<문제정의/문제파악을 위한 세부 프로세스>\n",
    "\n",
    "비즈니스 문제 파악 \n",
    "\n",
    "머신러닝 문제로 전환\n",
    "\n",
    "머신러닝 도입 가능성/필요성 검토\n",
    "\n",
    "효과 검증 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbde2dc5",
   "metadata": {},
   "source": [
    "Define the Problem\n",
    "\n",
    "비즈니스 문제를 파악한 후에 이를 해결하기 위한 \n",
    "데이터 과학과 머신러닝 문제로 전환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28458ee",
   "metadata": {},
   "source": [
    "Type of Machine Learning\n",
    "\n",
    "Supervised Learning(지도학습) - 예측\n",
    "- Develop Predictivel Model\n",
    "  based on Input & Output Data\n",
    "  \n",
    "Unsupervised Learning(비지도학습) - 패턴분석\n",
    "- Group and Interpret Data \n",
    "  based on only Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3399ab5",
   "metadata": {},
   "source": [
    "Type of Machine Learning\n",
    "\n",
    "Supervised Learning(지도학습)\n",
    "\n",
    "INPUT      OUTPUT\n",
    "고양이그림  고양이            Learning\n",
    "고양이그림  고양이               ->              Predictive\n",
    "닭그림      고양이 아님                           Model\n",
    "돼지그림    고양이 아님                     ↙\n",
    "-            \n",
    "            고양이같은 그림   Predictive  -> 고양이로 판명\n",
    "            \n",
    "지도학습\n",
    "OUTPUT - labeling 일관적인 데이터 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfedcc76",
   "metadata": {},
   "source": [
    "Type of Machine Learning\n",
    "\n",
    "Unsupervised Learning(비지도학습)\n",
    "\n",
    "INPUT  \n",
    "닭 개              Learning          닭 닭\n",
    "개 돼지              ->              개 개\n",
    "고양이 닭                            고양이 돼지\n",
    "\n",
    "유사한 특징을 가진 데이터들을 모음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aaa01b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5114cb9",
   "metadata": {},
   "source": [
    "머신러닝 업무 익히기(2)\n",
    "현실의 문제를 머신러닝의 문제로, 효과검증 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e6f35d",
   "metadata": {},
   "source": [
    "Supervised Learning\n",
    "\n",
    "Classification(분류 범주를 예측)\n",
    "\n",
    "Regression(회귀 숫자를 예측)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af37275e",
   "metadata": {},
   "source": [
    "Unsupervised Learning\n",
    "\n",
    "Clustering(유사한 그룹끼리 군집화)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a99e0fb",
   "metadata": {},
   "source": [
    "현실의 문제를 머신러닝 문제로\n",
    "\n",
    "\n",
    "Business Problem                         Target/Output           ML Problem\n",
    "\n",
    "고객이 서비스를 이탈할 것인가?             범주 : 이탈여부         Classification\n",
    "\n",
    "내년도 서비스 예상 매출액은 얼마 인가       숫자 : 매축액            Regression\n",
    "\n",
    "사용자 정보와 구매이력 기반 고객 세분화                             Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e9a9ef",
   "metadata": {},
   "source": [
    "기타 머신러닝 문제\n",
    "\n",
    "Recommender System 추천 시스템\n",
    "\n",
    "Anomaly Detection 이상 탐지\n",
    "\n",
    "Network Analysis 네트워크분석\n",
    "\n",
    "Dimensionality Reduction 차원 축소\n",
    "\n",
    "Profiling 프로파일링\n",
    "\n",
    "Time series Forecasting 시계열 예측 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cec88c",
   "metadata": {},
   "source": [
    "효과 검증 설계\n",
    "\n",
    "머신러닝 도입에 따른 효과 검증 프레임워크\n",
    "\n",
    "문제 정의\n",
    "   ↓\n",
    "가설 설정\n",
    "   ↓\n",
    "해결 방안\n",
    "   ↓\n",
    "효과 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60de38f",
   "metadata": {},
   "source": [
    "효과검증 설계 예시\n",
    "\n",
    "머신러닝 도입에 따른 효과 검증 프레임워크\n",
    "\n",
    "문제 정의   :   사용자의 서비스 재방문율(Retention)을 높이고 싶다\n",
    "   ↓\n",
    "가설 설정   :   사용자가 서비스를 이탈할 것 같은 시점에 \n",
    "   ↓          프로모션/혜택을 제공하여 재방문하게 한다\n",
    "해결 방안   :   서비스 이탈 예측 모델을 개발한다\n",
    "   ↓\n",
    "효과 검증   :   사용자의 재방문율(Retention)이 증가했는지 확인한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2767b83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faecc017",
   "metadata": {},
   "source": [
    "머신러닝 업무 익히기(2)\n",
    "머신러닝 모델 구축과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba0652d",
   "metadata": {},
   "source": [
    "머신 러닝 업무 프로세스\n",
    "\n",
    "1. 문제 파악 문제 정의\n",
    "\n",
    "2. 데이터 준비\n",
    "\n",
    "3. 모덱 구축 & 평가      V\n",
    "\n",
    "4. 결과 공유\n",
    "\n",
    "5. 모니터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b88e52",
   "metadata": {},
   "source": [
    "Build Model & Evaluation\n",
    "\n",
    "머신러닝 문제로 전환하고 데이터 준비를 마친 이후에는\n",
    "적절한 머신러닝 모델 & 알고리즘을 선택하여 모델을 구축하고 평가\n",
    "\n",
    "<모델 구축 & 평가를 위한 세부 프로세스>\n",
    "\n",
    "모델 & 알고리즘 선택\n",
    "\n",
    "실무적 제약사항 고려한 모델 적합\n",
    "\n",
    "하이퍼파라미터 설정\n",
    "\n",
    "모델 할습\n",
    "\n",
    "모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f0b07",
   "metadata": {},
   "source": [
    "모델 & 알고리즘 선택\n",
    "\n",
    "ML Model          Algorithm                       Result\n",
    "Classification    Logistic Regression             범주 에측\n",
    "  (분류)           Decision Tree\n",
    "                  Support Vector Machine\n",
    "                  \n",
    "Regression        Linear Regression               숫자 예측\n",
    "   (회귀)         Ridge Regression\n",
    "                  Lasso Regression\n",
    "                  \n",
    "Clustering        K-means                         군집\n",
    "                  DBscan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f12e201",
   "metadata": {},
   "source": [
    "머신러닝 관점 모델 평가(1)\n",
    "\n",
    "Regression은 실제값(y)과 예측한 값(y)의 차이\n",
    "오차(Loss/Cost/Error)를 통해 모델의 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5923a",
   "metadata": {},
   "source": [
    "머신러닝 관점 모델 평가(2)\n",
    "\n",
    "Classification은 실제 범주(actual)와 예측한 범주(predicted)의\n",
    "일치하는 정도(Loss/Cost/Error)를 통해 모델의 성능 평가\n",
    "\n",
    "Accuracy : 옳게 분류한 정확도\n",
    "Confusion Matrix : 분류 결과를 2x2의 표로 정리한 혼동 행렬\n",
    "F-measure : precision과 recall의 조화평균\n",
    "AUC : TPR과 FPR을 각각 x축과 y축ㅇ느로 했을 때의 생성되는 ROC curve 아래의 면적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d32eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "974fa390",
   "metadata": {},
   "source": [
    "이터 Feature 설명\n",
    "Bank Target Marketing 데이터는 다음과 같이\n",
    "\n",
    "은행의 고객 데이터\n",
    "최근 마케팅과 관련된 정보\n",
    "사회, 경제적인 지표\n",
    "3개의 영역에 대해서 20개의 feature로 구성되어 있습니다.\n",
    "\n",
    "Target은 마케팅을 통해 ‘정기예금’ 상품에 가입했는지 안 했는지 가입 여부에 대한 결과입니다.\n",
    "\n",
    "아래는 각 영역별로 속한 feature에 대한 상세 설명입니다.\n",
    "\n",
    "1) 은행의 고객 데이터\n",
    "Feature\tDescription\tType\n",
    "age\t나이\t숫자\n",
    "job\t직업\t범주\n",
    "marital\t결혼상태\t범주\n",
    "education\t교육\t범주\n",
    "default\tcredit 불이행\t범주\n",
    "housing\t주택융자 있는지\t범주\n",
    "loan\t개인융자 있는지\t범주\n",
    "2) 최근 마케팅과 관련된 정보\n",
    "Feature\tDescription\tType\n",
    "contact\t연락 방법\t범주\n",
    "month\t최근 연락한 달\t범주\n",
    "day_of_week\t최근 연락한 요일\t범주\n",
    "duration\t최근 연락한 시간(몇초 통화)\t숫자\n",
    "campaign\t이번 마케팅을 위해 연락한 횟수\t숫자\n",
    "pdays\t이전 마케팅 이후 최근 연락까지 걸린 일 수\t숫자\n",
    "previous\t이전 마케팅에서 연락한 횟수\t숫자\n",
    "poutcome\t이전 마케팅의 결과\t범주\n",
    "3) 사회, 경제적인 지표\n",
    "Feature\tDescription\tType\n",
    "emp.var.rate\t고용 변화율\t숫자\n",
    "cons.price.idx\t소비자 물가 지수\t숫자\n",
    "cons.conf.idx\t소비자 신뢰 지수\t숫자\n",
    "euribor3m\t유리보 (유로화를 사용하는 유럽연합 은행간 금리)\t숫자\n",
    "nr.employed\t직원 수\t숫자\n",
    "4) Target\n",
    "Feature\tDescription\tType\n",
    "y\t고객이 정기예금에 가입할 것인지\t범주"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76abff3c",
   "metadata": {},
   "source": [
    "데이터 샘플\n",
    "왼쪽 데이터 Feature 설명을 참고하여 Bank Target Marketing 데이터를 살펴보세요.\n",
    "\n",
    "age\tjob\tmarital\teducation\tdefault\thousing\tloan\tcontact\tmonth\tday_of_week\tduration\tcampaign\tpdays\tprevious\tpoutcome\temp.var.rate\tcons.price.idx\tcons.conf.idx\teuribor3m\tnr.employed\ty\n",
    "48\tadmin.\tmarried\tuniversity.degree\tno\tyes\tyes\tcellular\tnov\tfri\t89\t1\t999\t1\tfailure\t-0.1\t93.200\t-42.0\t4.021\t5195.8\t0\n",
    "37\ttechnician\tmarried\tuniversity.degree\tno\tno\tno\ttelephone\tmay\tthu\t263\t4\t999\t0\tnonexistent\t1.1\t93.994\t-36.4\t4.860\t5191.0\t0\n",
    "41\tservices\tmarried\thigh.school\tno\tyes\tno\tcellular\tapr\tthu\t60\t2\t999\t0\tnonexistent\t-1.8\t93.075\t-47.1\t1.410\t5099.1\t0\n",
    "36\tblue-collar\tsingle\tbasic.6y\tNaN\tno\tno\tcellular\tmay\ttue\t141\t1\t999\t1\tfailure\t-1.8\t92.893\t-46.2\t1.344\t5099.1\t0\n",
    "53\tblue-collar\tmarried\tbasic.9y\tno\tno\tno\ttelephone\tmay\twed\t178\t1\t999\t0\tnonexistent\t1.1\t93.994\t-36.4\t4.859\t5191.0\t0\n",
    "47\tadmin.\tmarried\thigh.school\tNaN\tno\tyes\tcellular\tapr\tfri\t517\t1\t999\t0\tnonexistent\t-1.8\t93.075\t-47.1\t1.405\t5099.1\t0\n",
    "33\tadmin.\tsingle\tuniversity.degree\tno\tno\tno\tcellular\tmay\tmon\t26\t4\t999\t0\tnonexistent\t-1.8\t92.893\t-46.2\t1.244\t5099.1\t0\n",
    "42\tadmin.\tmarried\tuniversity.degree\tno\tno\tno\ttelephone\tmay\tthu\t129\t2\t999\t0\tnonexistent\t1.1\t93.994\t-36.4\t4.860\t5191.0\t0\n",
    "30\tadmin.\tsingle\thigh.school\tno\tyes\tno\tcellular\tnov\twed\t195\t2\t999\t0\tnonexistent\t-0.1\t93.200\t-42.0\t4.120\t5195.8\t0\n",
    "41\tblue-collar\tdivorced\tbasic.4y\tNaN\tyes\tno\ttelephone\tmay\tmon\t1575\t1\t999\t0\tnonexistent\t1.1\t93.994\t-36.4\t4.857\t5191.0\t1\n",
    "49\tblue-collar\tmarried\tbasic.9y\tno\tyes\tno\tcellular\tapr\tfri\t832\t2\t999\t0\tnonexistent\t-1.8\t93.075\t-47.1\t1.405\t5099.1\t0\n",
    "38\tservices\tmarried\thigh.school\tno\tyes\tyes\ttelephone\tmay\tmon\t506\t1\t999\t0\tnonexistent\t1.1\t93.994\t-36.4\t4.857\t5191.0\t0\n",
    "40\thousemaid\tsingle\tuniversity.degree\tno\tyes\tno\ttelephone\tjun\tfri\t253\t2\t999\t0\tnonexistent\t1.4\t94.465\t-41.8\t4.959\t5228.1\t0\n",
    "37\tadmin.\tmarried\tuniversity.degree\tno\tyes\tno\tcellular\tnov\tfri\t450\t1\t999\t0\tnonexistent\t-0.1\t93.200\t-42.0\t4.021\t5195.8\t0\n",
    "45\tblue-collar\tdivorced\tbasic.4y\tNaN\tyes\tno\tcellular\tjul\tfri\t328\t1\t999\t0\tnonexistent\t1.4\t93.918\t-42.7\t4.957\t5228.1\t0\n",
    "53\tblue-collar\tmarried\tbasic.9y\tno\tyes\tno\tcellular\taug\tfri\t58\t1\t999\t0\tnonexistent\t1.4\t93.444\t-36.1\t4.964\t5228.1\t0\n",
    "51\tblue-collar\tmarried\tbasic.4y\tNaN\tyes\tno\tcellular\tjul\tmon\t301\t6\t999\t0\tnonexistent\t1.4\t93.918\t-42.7\t4.962\t5228.1\t0\n",
    "26\tself-employed\tsingle\tuniversity.degree\tno\tno\tno\tcellular\tmay\twed\t119\t1\t3\t1\tsuccess\t-1.8\t92.893\t-46.2\t1.270\t5099.1\t1\n",
    "44\tadmin.\tmarried\tbasic.4y\tNaN\tyes\tyes\ttelephone\tmay\ttue\t139\t5\t999\t0\tnonexistent\t1.1\t93.994\t-36.4\t4.856\t5191.0\t0\n",
    "44\ttechnician\tmarried\thigh.school\tno\tno\tno\ttelephone\tjun\tmon\t360\t3\t999\t0\tnonexistent\t1.4\t94.465\t-41.8\t4.865\t5228.1\t0\n",
    "37\tadmin.\tmarried\tuniversity.degree\tno\tyes\tno\tcellular\tnov\tmon\t386\t2\t999\t0\tnonexistent\t-0.1\t93.200\t-42.0\t4.191\t5195.8\t0\n",
    "36\ttechnician\tmarried\tuniversity.degree\tno\tno\tno\tcellular\tnov\twed\t221\t4\t999\t0\tnonexistent\t-0.1\t93.200\t-42.0\t4.120\t5195.8\t0\n",
    "38\ttechnician\tmarried\tprofessional.course\tno\tyes\tno\ttelephone\tmay\ttue\t76\t1\t999\t0\tnonexistent\t1.1\t93.994\t-36.4\t4.856\t5191.0\t0\n",
    "50\tmanagement\tdivorced\tuniversity.degree\tno\tyes\tno\tcellular\tnov\tfri\t21\t11\t999\t0\tnonexistent\t-0.1\t93.200\t-42.0\t4.021\t5195.8\t0\n",
    "31\tadmin.\tmarried\tuniversity.degree\tno\tyes\tno\tcellular\tsep\tfri\t232\t2\t13\t1\tsuccess\t-1.1\t94.199\t-37.5\t0.879\t4963.6\t1\n",
    "41\tblue-collar\tmarried\tbasic.9y\tNaN\tyes\tno\ttelephone\tjun\tthu\t512\t1\t999\t0\tnonexistent\t1.4\t94.465\t-41.8\t4.961\t5228.1\t1\n",
    "33\tadmin.\tsingle\thigh.school\tNaN\tno\tno\tcellular\tmay\tthu\t1723\t1\t12\t1\tsuccess\t-1.8\t92.893\t-46.2\t1.266\t5099.1\t1\n",
    "40\ttechnician\tmarried\tprofessional.course\tNaN\tno\tno\ttelephone\tjun\tmon\t60\t2\t999\t0\tnonexistent\t1.4\t94.465\t-41.8\t4.960\t5228.1\t0\n",
    "45\tadmin.\tmarried\tbasic.6y\tNaN\tyes\tno\ttelephone\tmay\tthu\t124\t1\t999\t0\tnonexistent\t1.1\t93.994\t-36.4\t4.860\t5191.0\t0\n",
    "33\tadmin.\tmarried\tuniversity.degree\tno\tyes\tno\tcellular\taug\tthu\t118\t1\t999\t0\tnonexistent\t1.4\t93.444\t-36.1\t4.968\t5228.1\t0\n",
    "출처 : [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada95aa8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b33c70",
   "metadata": {},
   "source": [
    "실습 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06232ff4",
   "metadata": {},
   "source": [
    "모델 평가\n",
    "\n",
    "경우에 따라서는 모델 도입을 통해 기대되는 손익이 더 중요할 수 있음\n",
    "\n",
    "Expected Value = P(X1) x V1 + P(X2) x V2 + ....\n",
    "\n",
    "기대 손익(Expected Value)은 어떤 이벤트가 발생할 확률 P(x)과\n",
    "그로 인해 발생하는 손익 V을 계산하여 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f438f0",
   "metadata": {},
   "source": [
    "혼동 행렬\n",
    "\n",
    "혼동 행렬(Confusion Matrix)은\n",
    "분류 모델의 성능을 \n",
    "평가할 때 사용하는 지표\n",
    "_\n",
    "                                Predicted\n",
    "                        True              False\n",
    "          True    True Positive(TP), False Negative(FN),\n",
    "Actual\n",
    "         False    False Positive(FP), True Negative(TN)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b46258",
   "metadata": {},
   "source": [
    "확률 행렬\n",
    "\n",
    "확률 행렬(Matrix of probabilites)은\n",
    "혼동행렬 값을 확률로 정규화 한 행렬\n",
    "\n",
    "Ex. True Positive/Total = P(True, True)\n",
    "\n",
    "_\n",
    "                                Predicted\n",
    "                        True              False\n",
    "          True    P(True, True),      P(True, False)\n",
    "Actual\n",
    "         False    P(False, True),     P(False, False)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3d232c",
   "metadata": {},
   "source": [
    "확률 행렬과 비용편익 분석을 통한 모델 평가\n",
    "\n",
    "확률 행렬\n",
    "Confusion Matrix\n",
    "   P(True, True),      P(True, False)\n",
    "   P(False, True),     P(False, False)\n",
    "   \n",
    "↓\n",
    "\n",
    "X\n",
    "\n",
    "↓\n",
    "\n",
    "비용편익 분석\n",
    "Cost-Benefit Matrix\n",
    "   Benefit-Value    Cost-Value\n",
    "   Cost-Value       Venefit-Value\n",
    "\n",
    "↓\n",
    "\n",
    "기대손익\n",
    "EV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc0ca7",
   "metadata": {},
   "source": [
    "타겟 마케팅 혼동 행렬과 확률 행렬 예시\n",
    "\n",
    "혼동 행렬\n",
    "Confusion Matrix\n",
    "_\n",
    "                                Predicted\n",
    "                        True              False\n",
    "          True    True Positive(TP), False Negative(FN),\n",
    "                        43명              19명\n",
    "Actual\n",
    "-\n",
    "         False    False Positive(FP), True Negative(TN)\n",
    "                         6명              32명\n",
    "                                                     total 100명\n",
    "↓\n",
    "정규화\n",
    "↓\n",
    "\n",
    "확률 행렬\n",
    "Matrix of probalites\n",
    "_\n",
    "                                Predicted\n",
    "                        True              False\n",
    "          True    P(True, True),      P(True, False)\n",
    "                        0.43               0.19\n",
    "Actual\n",
    "-\n",
    "         False    P(False, True),     P(False, False)\n",
    "                        0.06               0.32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a942e1e",
   "metadata": {},
   "source": [
    "타겟 마케팅에 대한 기대손익 예시\n",
    "\n",
    "분류 예측 결과에 따라 프로모션을 제공했을 때 기대되는 손익\n",
    "Expected Value = (0.43 x 9760) + (0.19 x 0) + (0.06 x - 230) + (0.32 x 0 ) = 4183\n",
    "\n",
    "+9760 = 판매 수익 - 마케팅비용 - 기타비용\n",
    "-230 = - 마케팅비용 - 기타비용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ed666",
   "metadata": {},
   "source": [
    "모델 평가\n",
    "\n",
    "머신러닝 관점에서 정확도가 높고\n",
    "비즈니스 관점에서 기대손익이 좋은 모델을 최종 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6206e4cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d5f8249",
   "metadata": {},
   "source": [
    "누구에게\n",
    "프로모션을 제공해야할까?\n",
    "실습 소개\n",
    "누구에게 타겟 마케팅을 하는 것이 좋을까요?\n",
    "\n",
    "이번 실습에서는 이전 마케팅 활동에 대한 41,259명의 데이터를 사용하여 머신러닝 모델을 만들어 볼 것입니다.\n",
    "\n",
    "그리고 새로운 데이터 3,952명에 대해서 실제로 마케팅에 응할 것인지 예측해보고 머신러닝 관점에서 모델을 평가해볼 것입니다.\n",
    "\n",
    "\n",
    "\n",
    "(1) 실습 순서\n",
    "이전 시간에 배웠던 Data Preprocessing이나 Feature Engineering 기법들을 사용하여 데이터를 준비하겠습니다.\n",
    "\n",
    "데이터가 준비되면 이번 주에 배웠던 내용을 활용해서 알고리즘을 선택하여 모델을 학습하세요.\n",
    "\n",
    "모델 학습이 완료되면 학습된 모델을 사용하여 3,952명에 대한 테스트가 진행됩니다.\n",
    "결과는 이번 주 배웠던 Confusion Matrix와 ROC Curve로 확인할 수 있습니다.\n",
    "\n",
    "(2) 실습 방법\n",
    "아래의 스위치 정보를 참고하여 머신러닝 모델을 학습시켜봅니다.\n",
    "\n",
    "스위치 정보값을 바꿔가며 다양하게 실습해보세요.\n",
    "\n",
    "<스위치 정보>\n",
    "\n",
    "스위치 이름\t스위치 역할\t입력가능한 값\n",
    "handling_missing_value_1\t하나의 행(row) 안에 결측치가 몇개 이상이면 그 row를 제거할 것인지 결정합니다\t0, 1, 2, 3, 4, 5 …\n",
    "handling_missing_value_2\t남아있는 결측치를 Numeric은 ‘중앙값’으로 Categorical은 ‘최다빈도값’으로 대체합니다\tTrue or False\n",
    "add_age_categorical\t연령과 관련한 범주형 변수를 새로 생성합니다\tTrue or False\n",
    "add_marketing_info\t이전 마케팅 정보 feature를 추가합니다\tTrue or False\n",
    "add_social_economic_info\t사회, 경제 지표 feature를 추가합니다\tTrue or False\n",
    "transform_pdays_to_categorical\tpdays를 범주형으로 변환하고, 변환하지 않으면 결측이 많아 제거합니다\tTrue or False\n",
    "transform_duration_to_log_scale\tduration의 데이터를 정규 분포형태로 log scaling으로 변환합니다\tTrue or False\n",
    "feature_normalization\tNumerical Feature에 대해서 값을 표준화합니다\tNone, ‘minmax’, ‘standard’\n",
    "model_selection\t학습할 머신러닝 모델 알고리즘을 선택합니다\t‘logistic_regression’, 이하 주석 참고\n",
    "\n",
    "지시사항\n",
    "스위치 정보를 참고하여 원하는 값으로 스위치 정보를 입력해주세요.\n",
    "\n",
    "실행 버튼을 눌러 Confusion Matrix와 ROC Curve 결과를 확인하세요.\n",
    "\n",
    "다양한 스위치 정보를 입력해보며 결과를 확인해보세요.\n",
    "아래 예시와 동일하게 스위치 값을 입력하고, 실행 버튼을 눌러 결과를 확인한 후, 제출 버튼을 눌러보세요.\n",
    "\n",
    "switch = {\n",
    "    'handling_missing_value_1' : 0,\n",
    "    'handling_missing_value_2' : True, \n",
    "    'add_age_categorical' : True,  \n",
    "    'add_marketing_info' : True, \n",
    "    'add_social_economic_info' : True, \n",
    "    'transform_pdays_to_categorical' : False,             \n",
    "    'transform_duration_to_log_scale' : True, \n",
    "    'feature_normalization' :  'standard', \n",
    "    'model_selection' :  'decision_tree'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main.py\n",
    "from target_marketing import *\n",
    "\n",
    "\n",
    "\n",
    "def predictive_model_for_target_marketing():\n",
    "    \n",
    "    '''\n",
    "    아래 준비된 9개의 스위치의 값을 변경하면서\n",
    "    타겟마케팅을 했을 때 응할 것 같은 고객을 예측하기 위한 머신러닝 모델을 만들어보세요.\n",
    "    \n",
    "    ※주의!  \"#\" 뒤에 있는 값만 입력해주세요!\n",
    "    '''\n",
    "    switch = {\n",
    "        'handling_missing_value_1' : 0, # 0, 1, 2, 3, 4, 5, ...\n",
    "        'handling_missing_value_2' : True, # True or False\n",
    "        'add_age_categorical' : True,  #True or False\n",
    "        'add_marketing_info' : True, #True or False\n",
    "        'add_social_economic_info' : True, #True or False\n",
    "        'transform_pdays_to_categorical' : False, #True or False\n",
    "        'transform_duration_to_log_scale' : True, #True or False\n",
    "        'feature_normalization' : 'standard', # None, 'minmax', 'standard'\n",
    "        'model_selection' : 'decision_tree' # ['linear_regression','logistic_regression', 'decision_tree',\n",
    "                                                  # 'knn', 'ridge_regression', 'k-means', 'lasso_regression',\n",
    "                                                  # 'naive_bayes', 'neural_network', 'random_forest']    \n",
    "    }\n",
    "    \n",
    "    execute_machine_learning_system(switch)\t\t\n",
    "    \n",
    "    return switch\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictive_model_for_target_marketing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  target_marketing.py\n",
    "import math\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score, accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import elice_utils\n",
    "\n",
    "pd.set_option('display.max_columns', 22)\n",
    "\n",
    "\n",
    "def execute_machine_learning_system(switch):\n",
    "    def load_dataset():\n",
    "        bank = pd.read_csv('./data/bank.csv', sep=';')\n",
    "        bank.replace('unknown', np.nan, inplace=True)\n",
    "        bank['y'].replace({'no':0, 'yes':1}, inplace=True)\n",
    "        return bank\n",
    "    \n",
    "    def check_missing_values(df):\n",
    "        df_null = df.isnull().sum()\n",
    "        print(\">> Bank Marketing 데이터의 변수별 결측치 비율은 다음과 같습니다.\")\n",
    "        for col, val in df_null.items():\n",
    "            print(\"{} : {:.2f}%\".format(col, val/df.shape[0]*100))\n",
    "    \n",
    "    def get_null_columns(df):\n",
    "        null_sum = df.isnull().sum()\n",
    "        null_cols = df.columns[np.where(null_sum>0)].values\n",
    "        print(\">> Missing Value가 있는 컬럼 : \", null_cols)\n",
    "        return null_cols\n",
    "    \n",
    "    def set_dtypes(df, num_cols, cat_cols):\n",
    "        for col in df.columns:\n",
    "            if col in cat_cols:\n",
    "                df[col] = df[col].astype(np.object)\n",
    "            elif col in num_cols:\n",
    "                df[col] = df[col].astype(np.float)\n",
    "                \n",
    "    def label_encoding_categorical(df):\n",
    "        for col, dtype in zip(df.columns, df.dtypes):\n",
    "            if dtype == np.object:\n",
    "                df[[col]] = df[[col]].apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    def create_dataset(df):\n",
    "        idx = df.dropna(axis=0).index\n",
    "        test_idx = np.random.RandomState(68).choice(idx, 3952)\n",
    "        train_idx = ~bank.index.isin(test_idx)\n",
    "        x = df.drop('y', axis=1).copy()\n",
    "        y = df[['y']]\n",
    "        \n",
    "        x_train = x.loc[train_idx]\n",
    "        x_test = x.loc[test_idx]\n",
    "        y_train = y.loc[train_idx].values.ravel()\n",
    "        y_test = y.loc[test_idx].values.ravel()\n",
    "\n",
    "        print('>> Create Dataset : 모델 학습을 위해 최종 데이터를 생성합니다.')\n",
    "        return  x, x_train, x_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    \n",
    "    #컨트롤러\n",
    "    def handling_missing_value(strategy1=None, strategy2=None):\n",
    "        if strategy1 is None and strategy2 is None:\n",
    "            print(\"[INFO] Handling Missing Value : 아무런 정보를 입력하지 않아 실행되지 않습니다.\")\n",
    "            return None\n",
    "        \n",
    "        if strategy1 is None: #전략1: 결측치가 있는 row는 제거. 몇개까지 row안에 결측치가 있는지 허용할거냐\n",
    "            pass\n",
    "        else:\n",
    "            remove_missing_value(bank, threshold=strategy1)\n",
    "            \n",
    "        if strategy2 is None:\n",
    "            pass\n",
    "        else:\n",
    "            if strategy2:\n",
    "                fill_missing_value(bank)\n",
    "            else:\n",
    "                remove_missing_value(bank, threshold=0)\n",
    "        sleep(1.2)\n",
    "\n",
    "    def add_age_categorical(strategy=True):\n",
    "        if strategy:\n",
    "            generate_feature_age(bank)\n",
    "            sleep(1.2)\n",
    "        else:\n",
    "            return None        \n",
    "            \n",
    "    def add_marketing_info(strategy=True):\n",
    "        if strategy:\n",
    "            print('>> Add Marketing Info Features : 이전 마케팅 정보 Feature를 사용합니다.')\n",
    "            sleep(1.2)\n",
    "        else:\n",
    "            remove_past_marketing_info(bank)\n",
    "    \n",
    "    def add_social_economic_info(strategy=True):\n",
    "        if strategy:\n",
    "            print('>> Add Social & Economic Info Features : 사회, 경제적인 정보 Feature를 사용합니다.')\n",
    "            sleep(1.2)\n",
    "        else:\n",
    "            remove_social_economic_info(bank)  \n",
    "    \n",
    "    def transform_pdays_to_categorical(strategy=True):\n",
    "        if strategy:\n",
    "            pdays_to_categorical(bank)\n",
    "            sleep(1.2)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def transform_duration_to_log_scale(strategy=True):\n",
    "        if strategy:\n",
    "            transform_duration(bank)\n",
    "            sleep(1.2)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def show_result_roc_curve(y_test, y_proba, y_predict, model='choosed_model'):\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        plot_roc_curve(fpr, tpr, model)\n",
    "        plt.savefig('roc_curve.svg', format='svg')\n",
    "        elice_utils.send_image(\"roc_curve.svg\")\n",
    "\n",
    "    def show_result_confusion_matrix(y_test, y_predict):\n",
    "        cnf_matrix_ = confusion_matrix(y_true=y_test.squeeze(), y_pred=y_predict)\n",
    "        plot_confusion_matrix(cnf_matrix_, classes=['Yes','No'], title='Confusion matrix')\n",
    "        plt.savefig('confusion_matrix.svg', format='svg')\n",
    "        elice_utils.send_image(\"confusion_matrix.svg\")\n",
    "\n",
    "    \n",
    "    #필요함수\n",
    "    ### Handling Missing Value\n",
    "    def remove_missing_value(df, threshold=0):\n",
    "        if type(threshold) != int:\n",
    "            print(\"[ERROR] threshold 에는 숫자(int)를 입력해주세요!\")\n",
    "            return None\n",
    "        if threshold < 0:\n",
    "            print(\"[ERROR] 0보다 작은 값을 입력할 수 없습니다.\")\n",
    "            return None\n",
    "        if threshold > 5:\n",
    "            threshold = 5\n",
    "        thresh = df.shape[1] - threshold\n",
    "        df.dropna(axis=0, thresh=thresh, inplace=True)\n",
    "        print(\">> Handling Missing Value : 결측치가 '제거'되었습니다.\")\n",
    "    \n",
    "    def fill_missing_value(df):\n",
    "        # num_cols, cat_cols, null_cols가 선행적으로 assign 되어 있어야 함\n",
    "        for col in null_cols:\n",
    "            if col in cat_cols:\n",
    "                _fill_most_frequent(df, col)\n",
    "            elif col in num_cols:\n",
    "                _fill_median(df, col)\n",
    "            else:\n",
    "                pass\n",
    "        print(\">> Handling Missing Value : 결측치가 '처리'되었습니다.\")\n",
    "    \n",
    "    def _fill_most_frequent(df, col):\n",
    "        most_frequent = df[col].value_counts().index[0] \n",
    "        df[col].fillna(most_frequent, inplace=True)\n",
    "        \n",
    "    def _fill_median(df, col):\n",
    "        median = df[col].median()\n",
    "        df[col].fillna(median, inplace=True)\n",
    "    \n",
    "    \n",
    "    ### Feature Generation\n",
    "    def generate_feature_age(df):\n",
    "        df['age_cat'] = pd.cut(df['age'], bins=[0, 25, 45, 60, np.inf], labels=[1, 2, 3, 4])\n",
    "        cat_cols.append('age_cat')\n",
    "        print('>> Generate Feature \"연령군\" : age 변수로부터 새로운 feature를 생성하였습니다.')\n",
    "    \n",
    "    \n",
    "    ### Feature Selection\n",
    "    def remove_past_marketing_info(df):\n",
    "        marketing_cols = ['contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays']\n",
    "        df.drop(marketing_cols, axis=1, inplace=True)\n",
    "        for col in marketing_cols:\n",
    "            if col in num_cols:\n",
    "                num_cols.remove(col)\n",
    "            elif col in cat_cols:\n",
    "                cat_cols.remove(col)\n",
    "    \n",
    "    def remove_social_economic_info(df):\n",
    "        social_economic_cols = ['emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "        df.drop(social_economic_cols, axis=1, inplace=True)\n",
    "        for col in social_economic_cols:\n",
    "            if col in num_cols:\n",
    "                num_cols.remove(col)\n",
    "            elif col in cat_cols:\n",
    "                cat_cols.remove(col)\n",
    "    \n",
    "    def choose_model_algorithm(model_selected='logistic_regression'):\n",
    "        model_list =  ['linear_regression','logistic_regression', 'decision_tree',\n",
    "\t\t\t\t\t   'knn', 'ridge_regression', 'k-means', 'lasso_regression',\n",
    "\t\t\t\t\t   'naive_bayes', 'neural_network', 'random_forest'] \n",
    "        if model_selected not in model_list:\n",
    "            s = '''모델 알고리즘을 아래 예시에 있는 것을 정확하게 입력했는지 확인해주세요.\\n{}'''.format(model_list)\n",
    "            raise ValueError(s)\n",
    "        if model_selected == 'logistic_regression':\n",
    "            model = LogisticRegression(fit_intercept=False, random_state=1234)\n",
    "            \n",
    "        elif model_selected == 'decision_tree':\n",
    "            model = DecisionTreeClassifier(criterion='gini', random_state=1234)\n",
    "            \n",
    "        elif model_selected == 'knn':\n",
    "            model = KNeighborsClassifier(n_neighbors = 10, weights='uniform', p=2, metric='euclidean')\n",
    "            \n",
    "        elif model_selected == 'naive_bayes':\n",
    "            model =  GaussianNB()\n",
    "            \n",
    "        elif model_selected == 'support_vector_machine':\n",
    "            model = SVC(kernel = 'sigmoid', random_state=1234)\n",
    "            \n",
    "        elif model_selected == 'neural_network':\n",
    "            model = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(8, 4), random_state=1234)\n",
    "            \n",
    "        elif model_selected == 'random_forest':\n",
    "            model = RandomForestClassifier(n_estimators = 20, random_state=1234)\n",
    "\n",
    "        elif model_selected == 'linear_regression':\n",
    "            s = '''선택한 모델 알고리즘 `{}`은 회귀(regression) 문제에 사용됩니다.\\n분류 문제를 위한 모델 알고리즘을 선택해주세요.'''.format(model_selected)\n",
    "            raise ValueError(s)\n",
    "\n",
    "        elif model_selected == 'ridge_regression':\n",
    "            s = '''선택한 모델 알고리즘 `{}`은 회귀(regression) 문제에 사용됩니다.\\n분류 문제를 위한 모델 알고리즘을 선택해주세요.'''.format(model_selected)\n",
    "            raise ValueError(s)\n",
    "\n",
    "        elif model_selected == 'lasso_regression':\n",
    "            s = '''선택한 모델 알고리즘 `{}`은 회귀(regression) 문제에 사용됩니다.\\n분류 문제를 위한 모델 알고리즘을 선택해주세요.'''.format(model_selected)\n",
    "            raise ValueError(s)\n",
    "\n",
    "        elif model_selected == 'k-means':\n",
    "            s = '''선택한 모델 알고리즘 `{}`은 군집화(clustering) 문제에 사용됩니다.\\n분류 문제를 위한 모델 알고리즘을 선택해주세요.'''.format(model_selected)\n",
    "            raise ValueError(s)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    ### Feature Transform\n",
    "    def pdays_to_categorical(df):\n",
    "        try:\n",
    "            pdays = df['pdays']\n",
    "    \n",
    "            df.loc[(pdays>=0) & (pdays<5), 'pdays'] = 1\n",
    "            df.loc[(pdays>=5) & (pdays<10), 'pdays'] = 2\n",
    "            df.loc[(pdays>=10) & (pdays<15), 'pdays'] = 3\n",
    "            df.loc[(pdays>=15) & (pdays<20), 'pdays'] = 4\n",
    "            df.loc[(pdays>=20) & (pdays<25), 'pdays'] = 5\n",
    "            df.loc[(pdays>=25) & (pdays<999), 'pdays'] = 6\n",
    "            df.loc[(pdays==999), 'pdays'] = 7\n",
    "            num_cols.remove('pdays')\n",
    "            cat_cols.append('pdays')\n",
    "            print('>> Transform Feature : Feature \"pdays\"가 Categorical Feature로 변환되었습니다.')\n",
    "        except KeyError:\n",
    "            print('[INFO] Transform \"pdays\" To Categorical : 이전 마케팅 정보를 사용하지 않으므로 실행되지 않습니다.')\n",
    "    \n",
    "    def remove_pdays(df):\n",
    "        df.drop('pdays', axis=1, inplace=True)\n",
    "        num_cols.remove('pdays')\n",
    "        \n",
    "    @np.vectorize\n",
    "    def log_ignore(x):\n",
    "        if x != 0:\n",
    "            return math.log(x)\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def transform_duration(df):\n",
    "        try:\n",
    "            df['duration'] = df['duration'].map(log_ignore)\n",
    "            print('>> Transform Feature : Feature \"duration\"이 Log Scale로 변환되었습니다.')\n",
    "        except:\n",
    "            print('[INFO] Transform Feature \"duration\" : 이전 마케팅 정보를 사용하지 않으므로 실행되지 않습니다.')\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    def cleansing_categorical(indices_categorical_columns):\n",
    "        categorical_pipline =  Pipeline(steps=[\n",
    "                        ('select', FunctionTransformer(lambda data: data[:, indices_categorical_columns])),\n",
    "                        ('onehot', OneHotEncoder(sparse=False))\n",
    "                    ])\n",
    "        return categorical_pipline\n",
    "    \n",
    "    \n",
    "    def cleansing_numeric(indices_numeric_columns, how=None):\n",
    "        if how is None:\n",
    "            print('>> Feature Normalization : feature의 scale을 그대로 사용합니다.')\n",
    "            numeric_pipeline = Pipeline(steps=[\n",
    "                            ('select', FunctionTransformer(lambda data: data[:, indices_numeric_columns])),\n",
    "                        ])\n",
    "            return numeric_pipeline\n",
    "        elif how == 'standard':\n",
    "            print('>> Feature Normalization : Feature를 Standardization으로 scaling합니다.')\n",
    "            numeric_pipeline = Pipeline(steps=[\n",
    "                            ('select', FunctionTransformer(lambda data: data[:, indices_numeric_columns])),\n",
    "                            ('scale', StandardScaler())\n",
    "                        ])\n",
    "            return numeric_pipeline\n",
    "        elif how == 'minmax':\n",
    "            print('>> Feature Normalization : Feature를 Min-Max 0과 1사이로 scaling합니다.')\n",
    "            numeric_pipeline = Pipeline(steps=[\n",
    "                            ('select', FunctionTransformer(lambda data: data[:, indices_numeric_columns])),\n",
    "                            ('scale', MinMaxScaler())\n",
    "                        ])\n",
    "            return numeric_pipeline\n",
    "        else:\n",
    "            s = '[ERROR] Feature Normalization을 위한 방법은 None, \"standard\", \"minmax\"로 정확하게 입력하셔야 합니다.'\n",
    "            raise ValueError(s)\n",
    "            \n",
    "    \n",
    "    def create_estimator(df, model, scaling=None):\n",
    "        indices_categorical_columns = df.dtypes == np.object\n",
    "        indices_numeric_columns = df.dtypes != np.object\n",
    "        if indices_categorical_columns.sum() != 0 and indices_numeric_columns.sum() != 0:\n",
    "            estimator = Pipeline(steps=[\n",
    "                ('cleansing', FeatureUnion(transformer_list=[\n",
    "                    ('categorical', cleansing_categorical(indices_categorical_columns)),\n",
    "                    ('numeric', cleansing_numeric(indices_numeric_columns, how=scaling))\n",
    "                ])),\n",
    "                ('modeling', model)\n",
    "            ])\n",
    "        elif indices_categorical_columns.sum() !=0 and indices_numeric_columns.sum() == 0:\n",
    "            estimator = Pipeline(steps=[\n",
    "                ('cleansing', FeatureUnion(transformer_list=[\n",
    "                    ('categorical', cleansing_categorical(indices_categorical_columns))\n",
    "                ])),\n",
    "                ('modeling', model)\n",
    "            ])\n",
    "        elif indices_categorical_columns.sum() ==0 and indices_numeric_columns.sum() != 0:\n",
    "            estimator = Pipeline(steps=[\n",
    "                ('cleansing', FeatureUnion(transformer_list=[\n",
    "                    ('numeric', cleansing_numeric(indices_numeric_columns, how=scaling))\n",
    "                ])),\n",
    "                ('modeling', model)\n",
    "            ])\n",
    "        else:\n",
    "            return None\n",
    "        return estimator\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    def plot_roc_curve(fpr, tpr, model, color=None) :\n",
    "        plt.style.use('seaborn-whitegrid')\n",
    "    \n",
    "        accuracy = round(accuracy_score(y_test.squeeze(), y_predict),8)*100\n",
    "        model = model + '\\n(AUC = {:0.3f}, Accuracy={:.2f}%)'.format(auc(fpr, tpr), accuracy)\n",
    "        \n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.plot(fpr, tpr, label=model, color=color, linewidth=4)\n",
    "        plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "        plt.axis([0,1,0,1])\n",
    "        plt.xlabel('FPR', fontsize=22)\n",
    "        plt.ylabel('TPR', fontsize=22)\n",
    "        plt.title('ROC curve', fontsize=35)\n",
    "        plt.legend(loc=\"lower right\", fontsize=19)\n",
    "    \n",
    "    def plot_confusion_matrix(cm, classes,\n",
    "                              normalize=False,\n",
    "                              title='Confusion matrix',\n",
    "                              cmap=plt.cm.Blues):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        plt.style.use('seaborn')\n",
    "        plt.figure(figsize=(7,7))\n",
    "        import itertools\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum()\n",
    "            title = 'Normalized Rate of Confusion Matrix'\n",
    "    \n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title, fontsize=35)\n",
    "        #plt.colorbar( fraction=0.046, pad=0.04, use_gridspec=True)\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45, fontsize=18)\n",
    "        plt.yticks(tick_marks, classes, fontsize=18)\n",
    "    \n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            \n",
    "            plt.text(j, i, format(cm[~i, ~j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\",fontsize=30)\n",
    "    \n",
    "        plt.ylabel('Actual label', fontsize=21)\n",
    "        plt.xlabel('Predicted label', fontsize=21)\n",
    "        plt.tight_layout()\n",
    "        plt.grid(False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #전략 선택 부분\n",
    "    switch_handling_missing_value_1 = switch['handling_missing_value_1']\n",
    "    switch_handling_missing_value_2 = switch['handling_missing_value_2']\n",
    "    switch_add_age_categorical = switch['add_age_categorical']\n",
    "    switch_add_marketing_info = switch['add_marketing_info']\n",
    "    switch_add_social_economic_info = switch['add_social_economic_info']\n",
    "    switch_transform_pdays_to_categorical = switch['transform_pdays_to_categorical']\n",
    "    switch_transform_duration_to_log_scale = switch['transform_duration_to_log_scale']\n",
    "    switch_feature_normalization = switch['feature_normalization']\n",
    "    model_selection = switch['model_selection']\n",
    "    \n",
    "    #준비\n",
    "    bank = load_dataset()\n",
    "    null_cols = get_null_columns(bank)\n",
    "    num_cols = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "    cat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "    \n",
    "    #전략 실행 부분\n",
    "    ## Data Preprocessing\n",
    "    handling_missing_value(strategy1=switch_handling_missing_value_1,\n",
    "                           strategy2=switch_handling_missing_value_2)\n",
    "    ### Feature Generation\n",
    "    add_age_categorical(strategy=switch_add_age_categorical)\n",
    "    add_marketing_info(strategy=switch_add_marketing_info)\n",
    "    add_social_economic_info(strategy=switch_add_social_economic_info)\n",
    "    ### Feature Transform\n",
    "    transform_pdays_to_categorical(strategy=switch_transform_pdays_to_categorical)\n",
    "    transform_duration_to_log_scale(strategy=switch_transform_duration_to_log_scale)\n",
    "    \n",
    "    # 최종데이터 셋 준비\n",
    "    set_dtypes(bank, num_cols, cat_cols)\n",
    "    label_encoding_categorical(bank)\n",
    "    set_dtypes(bank, num_cols, cat_cols)\n",
    "    x, x_train, x_test, y_train, y_test = create_dataset(bank)\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=3952, shuffle=True, stratify=y,random_state=13)\n",
    "    del bank\n",
    "    \n",
    "    # 모델학습\n",
    "    model = choose_model_algorithm(model_selection)\n",
    "    estimator = create_estimator(x, model, scaling=switch_feature_normalization)\n",
    "    estimator.fit(x_train, y_train)\n",
    "    \n",
    "    # 모델결과\n",
    "    #model_score = estimator.score(x_test, y_test)\n",
    "    y_predict = estimator.predict(x_test)\n",
    "    y_proba = estimator.predict_proba(x_test)[:, 1]\n",
    "    print('...')\n",
    "    sleep(1.9)\n",
    "    print('>>> 모델을 학습하는 중입니다.')\n",
    "    sleep(1.9)\n",
    "    print('>>> 모델 학습이 완료되었습니다. 학습된 모델을 사용해 3,952명에 대한 예측을 진행합니다.')\n",
    "    sleep(3)\n",
    "\n",
    "    # 시각화\n",
    "    print('=============================')\n",
    "    print('========= 예측 결과 =========')\n",
    "    print('=============================')\n",
    "    show_result_confusion_matrix(y_test, y_predict)\n",
    "    sleep(2.2)\n",
    "    show_result_roc_curve(y_test, y_proba, y_predict, model_selection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b063d",
   "metadata": {},
   "source": [
    "지시사항\n",
    "스위치 정보를 참고하여 원하는 값으로 스위치 정보를 입력해주세요.\n",
    "\n",
    "실행 버튼을 눌러 Confusion Matrix와 ROC Curve 결과를 확인하세요.\n",
    "\n",
    "다양한 스위치 정보를 입력해보며 결과를 확인해보세요.\n",
    "아래 예시와 동일하게 스위치 값을 입력하고, 실행 버튼을 눌러 결과를 확인한 후, 제출 버튼을 눌러보세요.\n",
    "\n",
    "switch = {\n",
    "    'handling_missing_value_1' : 0,\n",
    "    'handling_missing_value_2' : True, \n",
    "    'add_age_categorical' : True,  \n",
    "    'add_marketing_info' : True, \n",
    "    'add_social_economic_info' : True, \n",
    "    'transform_pdays_to_categorical' : False,             \n",
    "    'transform_duration_to_log_scale' : True, \n",
    "    'feature_normalization' :  'standard', \n",
    "    'model_selection' :  'decision_tree'\n",
    "}\n",
    "Copy\n",
    "\n",
    "지시사항\n",
    "이전 실습에서 지시한 switch 값으로 학습한 모델의 Confusion Matrix 값을 가져와 예시와 같이 입력하세요.\n",
    "\n",
    "(예시)\n",
    "\n",
    "true_positive = 94\n",
    "false_negative = 406\n",
    "false_positive = 58\n",
    "true_negative = 3394    \n",
    "Copy\n",
    "주의! 총 합이 3,952명이어야 합니다.\n",
    "\n",
    "실행 버튼을 눌러 결과값을 확인하고, 제출 버튼을 눌러보세요.\n",
    "\n",
    "이전 실습으로 돌아가 다양한 모델의 Confusion Matrix 값을 가져와 변수에 입력하고, 기대손익과 예상 수익을 평가해보며 비즈니스 관점에서 최고의 모델을 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main.py\n",
    "\n",
    "from model_evaluation import *\n",
    "\n",
    "def evaluate_expected_value():\n",
    "    \n",
    "    '''\n",
    "    [실습] 모델의 기대손익과 예상 수익 평가하기\n",
    "    \n",
    "    1) 이전 실습에서 Confusion Matrix의 결과값을 가져오세요\n",
    "        --------------------------------------\n",
    "        |                 |                  |\n",
    "        |  true_positive  |  false_negative  |\n",
    "        |                 |                  |\n",
    "        --------------------------------------\n",
    "        |                 |                  |\n",
    "        |  false_positive |  true_negative   |\n",
    "        |                 |                  |\n",
    "        --------------------------------------\n",
    "    \n",
    "    2) 아래에 각 값을 입력하세요 (총 3,952명을 대상으로 합니다)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 이전 실습에서 Confusion Matrix의 결과값을 가져와 입력하세요\n",
    "    true_positive = 253\n",
    "    false_negative = 247\n",
    "    false_positive = 271\n",
    "    true_negative = 3181\n",
    "    \n",
    "    \n",
    "    # 모델의 기대손익(expected value)과\n",
    "    # 모델을 사용했을 때의 예상 수익(revenue)을 확인합니다\n",
    "    expected_value(\n",
    "                    true_positive, false_negative,\n",
    "                    false_positive, true_negative\n",
    "                    )\n",
    "    \n",
    "    \n",
    "    return true_positive,false_negative,false_positive,true_negative\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_expected_value()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_evaluation.py\n",
    "\n",
    "def expected_value(tp, fn, fp, tn):\n",
    "    tp_value = 7380\n",
    "    fn_value = 0\n",
    "    fp_value = -2620\n",
    "    tn_value = 0\t\n",
    "    \n",
    "    total = tp + fn + fp + tn\n",
    "    input_true = tp + fn\n",
    "    input_false = fp + tn\n",
    "    if total != 3952:\n",
    "        s = '''예측 대상인 3,952명 보다 많거나 적은 수가 입력되었습니다.\\nConfusion Matrix에 적힌 수를 정확하게 입력해주시기 바랍니다.'''\n",
    "        raise ValueError('{}'.format(s))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ev = (tp/total * tp_value) + (fn/total * fn_value) + (fp/total * fp_value) + (tn/total * tn_value)\n",
    "    revenue = (tp * tp_value) + (fn * fn_value) + (fp * fp_value) + (tn * tn_value)\n",
    "    print(\"개발한 모델의 기대손익은 {:,.0f}원 입니다.\".format(ev))\n",
    "    print(\"개발한 모델을 사용하여 타겟마케팅을 진행했을 때 예상 수익은 {:,.0f}원 입니다.\".format(revenue))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
